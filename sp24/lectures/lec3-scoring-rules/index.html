<!DOCTYPE html><html lang="en-US"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=Edge"><link rel="shortcut icon" href="/favicon.ico" type="image/x-icon"><link rel="stylesheet" href="/assets/css/just-the-docs-default.css"> <script type="text/javascript" src="/assets/js/vendor/lunr.min.js"></script> <script type="text/javascript" src="/assets/js/just-the-docs.js"></script><meta name="viewport" content="width=device-width, initial-scale=1"><title>Lecture 3 - Scoring Rules | Stat 157/260</title><meta name="generator" content="Jekyll v3.9.0" /><meta property="og:title" content="Lecture 3 - Scoring Rules" /><meta name="author" content="Jean-Stanislas Denain" /><meta property="og:locale" content="en_US" /><meta name="description" content="Website for the UC Berkeley class STAT 165 / STAT 265." /><meta property="og:description" content="Website for the UC Berkeley class STAT 165 / STAT 265." /><link rel="canonical" href="http://forecastingclass.com/lectures/lec3-scoring-rules/" /><meta property="og:url" content="http://forecastingclass.com/lectures/lec3-scoring-rules/" /><meta property="og:site_name" content="Stat 157/260" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Lecture 3 - Scoring Rules" /> <script type="application/ld+json"> {"url":"http://forecastingclass.com/lectures/lec3-scoring-rules/","headline":"Lecture 3 - Scoring Rules","author":{"@type":"Person","name":"Jean-Stanislas Denain"},"description":"Website for the UC Berkeley class STAT 165 / STAT 265.","@type":"WebPage","@context":"https://schema.org"}</script><body> <svg xmlns="http://www.w3.org/2000/svg" style="display: none;"> <symbol id="svg-link" viewBox="0 0 24 24"><title>Link</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"><title>Search</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"><title>Menu</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"><title>Expand</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"><polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"><title>Document</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"><path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> </svg><div class="side-bar"><div class="site-header"> <a href="http://forecastingclass.com/" class="site-title lh-tight"> Stat 157/260 </a> <a href="#" id="menu-button" class="site-button"> <svg viewBox="0 0 24 24" class="icon"><use xlink:href="#svg-menu"></use></svg> </a></div><nav role="navigation" aria-label="Main" id="site-nav" class="site-nav"><ul class="nav-list"><li class="nav-list-item"><a href="http://forecastingclass.com/" class="nav-list-link">About</a><li class="nav-list-item"><a href="http://forecastingclass.com/calendar/" class="nav-list-link">Calendar</a></ul></nav><footer class="site-footer"> This site uses <a href="https://github.com/pmarsceill/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll.</footer></div><div class="main" id="top"><div id="main-header" class="main-header"><div class="search"><div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search Stat 157/260" aria-label="Search Stat 157/260" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label></div><div id="search-results" class="search-results"></div></div></div><div id="main-content-wrap" class="main-content-wrap"><div id="main-content" class="main-content" role="main"> <script type="text/javascript" async="" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/MathJax.js?config=TeX-MML-AM_CHTML"> MathJax.Hub.Config({ tex2jax: { inlineMath: [["$", "$"], ["\\(", "\\)"]], processEscapes: true } }); </script><h1 id="lecture-3-scoring-rules"> <a href="#lecture-3-scoring-rules" class="anchor-heading" aria-labelledby="lecture-3-scoring-rules"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Lecture 3: Scoring Rules</h1><p><i>Yan Zhang and Frances Ding</i><br /> <br /></p><p>We want to get better at predicting things, so the following question is very fundamental:</p><blockquote><p>How do we reward people for giving us better predictions?</p></blockquote><p>Let's start by thinking about how we might make a rule for this when there are 2 outcomes. For a natural first draft, we can just have you bet 1 unit of score at even odds. This means if you bet correctly on the desired outcome you will gain 1 point, and if you were wrong you will lose 1 point. For example, you can guess “the temperature tomorrow morning at 6AM will not be between 60 and 70 degrees.” If the temperature at 6AM ends up being 56 degrees, you will get 1 point.</p><p>Over time, it's clear that people who do well at this will in general score more in the long run. However, there's a way in which this rule fails to let people show their skills. For example, suppose for every single event with an actual probability of 60%, you are perfectly calibrated and know this, but Jean always thinks the probability is 100%. Under our naive draft, you two will always bet the same way, “yes”, in these events, but the relative skill between you will never be discovered. This gives rise to our first main idea - we need to show the distribution of a prediction, not just a single number.</p><p>So… draft 2! You bet on something like “it will snow tomorrow” by giving a probability $p$. Then, you get $p$ points if the event occurs. (so if you bet “90%”, then you get 0.9 points if it snows and 0.1 otherwise). This is better than the first draft since you are offering more information about your beliefs, but it has a very interesting flaw. So take a couple of minutes to think about this:</p><p>The answer is that if you think there's a 60% chance that it will snow, your optimal strategy is to actually bet 100%! This means while our draft 2 lets people show their skills, it also incentivizes them to hide their skills by betting something that doesn't represent what they actually think. While this is interesting from a game and psychology perspective, in the context where we are trying to see how to predict things better and/or get some information from what people are actually betting, we want to extract people's true beliefs about things. To mathematically formalize the things we wanted up to this point:</p><ol><li>Assume we have a finite number of outcomes $1, \ldots n$ in our sample space.<li>Our predictions should be distributions. That is, an assignment of $q_i$ to each $i$ so that they add up to 1. Let's call such a prediction $q$.<li>We want a <strong>scoring rule</strong>; that is, a way to assign points on what actually happened. We can call this rule $f(q, i)$.<li>We want a <strong>strictly proper scoring rule</strong>; that is, if you think the reality of the world is $(q_1, … q_n)$, then your prediction $q$ should actually be equal to $(q_1, … q_n)$ to maximize your expected score.</ol><h2 id="strictly-proper-scoring-rules"> <a href="#strictly-proper-scoring-rules" class="anchor-heading" aria-labelledby="strictly-proper-scoring-rules"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Strictly proper scoring rules</h2><p>So what's a good example of a strictly proper scoring rule? If you are only going to remember one, that would be <a href="https://rss.onlinelibrary.wiley.com/doi/10.1111/j.2517-6161.1952.tb00104.x">Good's</a> logarithmic scoring rule. This is defined by $(f(q, i) = \log(q_i)$, where we are using the natural log.</p><ul><li>As an example, suppose you bet that tomorrow it will rain with probability 20%, snow with probability 30%, and neither rain nor snow with probability 50%, then when it snows you will be “rewarded” $\log(0.3)$, which is roughly -1.2 points.<li>It might be weird to think of negative points as a reward, but you should see that you are getting something “less negative” than someone who assigned probability 10% to snowing, which would give them -2.3 points.<li>In machine learning, the logarithmic scoring rule often appears in the guise of the <strong>log loss</strong>.</ul><p>There are (infinitely!) many other strictly proper scoring rules, and a good second one to know is Brier's <strong>quadratic scoring rule</strong>. This rule assigns $[f(q, i) = -\sum_{j=1}^n (q_j - o_{ij})^2,]$ where $o_{ij} = 1$ if $i=j$ and $0$ otherwise. A few interesting things about this rule:</p><ul><li>It helps to do some algebra and simplify it. If you open the parentheses, you get $2q_i - 1 - \sum_{j=1}^n q_j^2$. One interpretation of this is that it fixes our naive (remember draft 2?) scoring rule of $q_i$ to have a “quadratic punishment” that disincentivizes to pushing the prediction all the way to 1 or 0.<li>You can think of this as the negative of the mean-squared error, which comes up often in statistics as a way of measuring “badness.” Note that the mean-squared error metric is also called the <strong>Brier score</strong>, which can be easily confused with Brier's quadratic scoring rule. They are just negatives of each other, so you want a <em>low</em> Brier score (since it measures error) but a <em>high</em> scoring rule outcome.</ul><p>There are pros and cons for both rules. For example, the logarithmic rule is more sensitive at small probabilities than the quadratic rule, which could be either good or bad depending on what you want to reward the forecaster for. Besides these concerns, it is always good to keep in mind that being strictly proper is not the be-all and end-all; there might be plenty of reasons to pick scoring rules that are “almost proper” but achieve other goals, such as being more intuitive for forecasters, having positivity and negativity be meaningful (for example, as stated all log scores are negative!), etc. See <a href="https://arxiv.org/pdf/1808.07501.pdf">Greenberg's paper</a> for some ideas in this direction.</p><h2 id="prediction-markets-and-platforms"> <a href="#prediction-markets-and-platforms" class="anchor-heading" aria-labelledby="prediction-markets-and-platforms"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Prediction Markets and Platforms</h2><p>Remember that our original goal was to reward people for making better predictions. A natural way to do this is to set up structures such as games and/or contests that reflect better predictive abilities. There are two major categories of such structures.</p><p>The first such category is called <strong>prediction markets</strong>. While this word is itself ambiguous, it typically means (such as in <a href="https://en.wikipedia.org/wiki/Prediction_market">Wikipedia</a>) classical financial markets where you buy or sell abstract objects that reflect your belief in an event that will resolve in the future.</p><ul><li>For example, on Predictit, one of the more popular prediction markets, you buy and sell “shares” of an event taking place. The price of the share will always be between 1 and 99 cents, which corresponds to what the market thinks the probability percentage of an event taking place is. For an outcome such as “it will snow tomorrow by 12PM PT”, you can buy “yes” shares when the price is too low (which drives up the price) or buy “no” shares when the price is too high (which drives down the price). When the market closes (the event resolves) successfully, if the event happened, then “yes” shares are now worth $1 and “No” shares become worthless, and the opposite happens if the event did not happen.<li>Sports betting is a pretty big industry (e.g. Betfair) working under similar structures. People frequently say things such as “the market thinks X” by interpreting the market state as a kind of prediction. For academics, another quite exciting prediction market of this type is the Iowa Electronic Markets, which has been a source of interesting <a href="https://iemweb.biz.uiowa.edu/research/">research</a> about the power of prediction markets.</ul><p style="text-align:center;"> <img src="https://bounded-regret.ghost.io/content/images/2022/01/predictit.png" width="50%" /></p><p><br /><i>An example Predictit market from Jan. 14, 2022 showing the latest prices for “yes” and “no” shares.</i></p><p>The second such category is something we call <strong>prediction platforms</strong>, where instead of trading, you enter predictions like how you would submit a structured answer to some sort of online exam, and then you get points based on a… (usually trying to be strictly proper) scoring rule!</p><ul><li>For example, on <a href="https://www.metaculus.com/questions/">Metaculus</a>, one of the more popular prediction platforms, you put in a probability of how likely you think an event will happen. You can also revise your estimates as time progresses, until the point when the question “closes” (usually after the event happens or after a certain amount of time has passed). Afterwards, your guesses are scored with a fairly complicated proper <a href="https://www.metaculus.com/help/faq/#scoring">scoring rule</a> that, at heart, is the logarithmic scoring rule, with some adjustments on top for rewarding you when you are “more right” than the rest of the community. There are also different scoring rules that are used for other types of questions, such as predicting a number versus a probability, or prediction tournaments.<li>Confusingly, sometimes “prediction markets” also refer to prediction platforms which use scoring rules as a basis, such as <a href="https://mason.gmu.edu/~rhanson/mktscore.pdf">Robin Hanson</a>'s “markets” made from scoring rules (in particular, this paper shows that the logarithmic scoring rule was the only rule to satisfy some nice properties such a market would want to enjoy).</ul><p>While the second type, prediction platforms, may end up being more directly relevant to our class, prediction markets are a good way to get priors and learn about what people think about some particular subject. We hope your predictive skills will be sharpened by interactions with both predictive markets and platforms!</p><p>(Thanks to Frances Ding, Alex Wei and Eric Neyman for help preparing this post. I also learned from and recommend Tim Roughgarden's computer science-oriented <a href="https://timroughgarden.org/f16/l/l17.pdf">lecture notes</a>)</p><hr /><h2 id="mathematical-tangent"> <a href="#mathematical-tangent" class="anchor-heading" aria-labelledby="mathematical-tangent"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Mathematical Tangent</h2><p>Here's a really nice way (h/t Eric Neyman) to see how the log and quadratic rules naturally appear, if we aren't afraid to do a bit of calculus. Let's consider our goal of finding a proper scoring function in a simplified case with just 2 outcomes (so $p_1 = p, p_2 = (1-p)$), which is to find a scoring function $f$ such that $p f(x) + (1-p) f(1-x)$ is maximized at $x=p$. Taking the derivative with respect to $x$ and setting equal to 0, we get $pf'(p) - (1-p)f'(1-p) = 0$, or $pf'(p) = (1-p)f'(1-p)$.</p><p>Now, let's turn the question around and ask our “wishful thinking” selves: what $f'()$ would make this work?</p><ol><li>A natural choice is $f'(p) = (1-p)$, because then the left and right hand sides are both $p(1-p)$.<li>Another natural choice is $f'(p) = 1/p$, because then the left and right hand sides are both 1.</ol><p>I leave the rest to you to see that these two options exactly correspond to the quadratic and log rules, respectively!</p></div></div><div class="search-overlay"></div></div>
