{"0": {
    "doc": "Announcements",
    "title": "Announcements",
    "content": "Announcements are stored in the _announcements directory and rendered according to the layout file, _layouts/announcement.html. ",
    "url": "http://localhost:4000/announcements/",
    "relUrl": "/announcements/"
  },"1": {
    "doc": "Announcements",
    "title": "Week 1 Announcement",
    "content": "Sep 28 &middot; 0 min read Hi everyone, this is an announcement for week 1. ",
    "url": "http://localhost:4000/announcements/",
    "relUrl": "/announcements/"
  },"2": {
    "doc": "Calendar",
    "title": "Calendar",
    "content": " ",
    "url": "http://localhost:4000/calendar/",
    "relUrl": "/calendar/"
  },"3": {
    "doc": "Calendar",
    "title": "Week 1",
    "content": "Jan 19 Lecture 1: Class Overview Notes / HW1 (due 01/24) / Course Overview / Slides Jan 21 Discussion 1: Calibration Discussion Worksheet / Reading (through end of Exercise 13-5) ",
    "url": "http://localhost:4000/calendar/#week-1",
    "relUrl": "/calendar/#week-1"
  },"4": {
    "doc": "Calendar",
    "title": "Week 2",
    "content": "Jan 24 Lecture 3: Scoring Rules Notes / HW2 (due 01/31) Jan 26 Lecture 4: Estimation Notes Jan 28 Discussion 2: Estimation Discussion Worksheet / Reading ",
    "url": "http://localhost:4000/calendar/#week-2",
    "relUrl": "/calendar/#week-2"
  },"5": {
    "doc": "Calendar",
    "title": "Week 3",
    "content": "Jan 30 Lecture 5: Zeroth and First Order Forecasting Notes / Slides / HW3 (due 02/07) Feb 1 Lecture 6: Base Rates and Reference Classes Notes / Slides Feb 3 Discussion 3 Discussion Worksheet ",
    "url": "http://localhost:4000/calendar/#week-3",
    "relUrl": "/calendar/#week-3"
  },"6": {
    "doc": "Calendar",
    "title": "Week 4",
    "content": "Feb 7 Lecture 7: The “Other” Option Slides / Notes / HW4 (due 02/14) / Data for HW4 Lab (also available in the lab Jupyter Notebook) / Reading (due 2/10) Feb 9 Lecture 8: Combining Forecasts (Part 1) Slides / Notes Feb 11 Discussion 4: The Inner Game of Forecasting Discussion Worksheet ",
    "url": "http://localhost:4000/calendar/#week-4",
    "relUrl": "/calendar/#week-4"
  },"7": {
    "doc": "Calendar",
    "title": "Week 5",
    "content": "Feb 13 Lecture 9: Combining Forecasts (Part 2) Slides / HW5 (due 2/22) / Notes / Reading (pages 1-8, due 2/17) Feb 15 Lecture 10: Common Probability Distributions Slides / Notes Feb 17 Discussion 5 Discussion Worksheet ",
    "url": "http://localhost:4000/calendar/#week-5",
    "relUrl": "/calendar/#week-5"
  },"8": {
    "doc": "Calendar",
    "title": "Week 6",
    "content": "Feb 20 President's Day Feb 22 Lecture 11: Prioritizing Information Slides / HW6 (due 02/28) / Notes ",
    "url": "http://localhost:4000/calendar/#week-6",
    "relUrl": "/calendar/#week-6"
  },"9": {
    "doc": "Calendar",
    "title": "Week 7",
    "content": "Feb 27 No Lecture Mar 1 Lecture 12: Turning Considerations Into Probabilities Slides / HW7 (due 3/7) / Notes Mar 3 Discussion 7 Discussion Worksheet ",
    "url": "http://localhost:4000/calendar/#week-7",
    "relUrl": "/calendar/#week-7"
  },"10": {
    "doc": "Calendar",
    "title": "Week 8",
    "content": "Mar 6 Lecture 13: Cognitive Biases Pt. 1 Slides / HW8 (due 3/15) / Reading Mar 8 Lecture 14: Cognitive Biases Pt. 2 Slides (same as previous) Mar 10 Discussion 8 Discussion Worksheet Version 1 / Discussion Worksheet Version 2 ",
    "url": "http://localhost:4000/calendar/#week-8",
    "relUrl": "/calendar/#week-8"
  },"11": {
    "doc": "Calendar",
    "title": "Week 9",
    "content": "Mar 13 Lecture 15: Information Hygiene Slides / Notes / HW9 (due 03/21) / Reading Mar 15 Lecture 16: Guest Lecture Slides Mar 17 Discussion 9 Discussion worksheet ",
    "url": "http://localhost:4000/calendar/#week-9",
    "relUrl": "/calendar/#week-9"
  },"12": {
    "doc": "Calendar",
    "title": "Week 10",
    "content": "Mar 20 Lecture 17: Belief are Martingales HW10 (due 04/04) / Notes Mar 22 Lecture 18: Independence Assumptions Final Project Description Mar 24 Discussion 10 ",
    "url": "http://localhost:4000/calendar/#week-10",
    "relUrl": "/calendar/#week-10"
  },"13": {
    "doc": "Calendar",
    "title": "Week 11",
    "content": "Mar 27 Spring Recess Mar 29 Spring Recess Mar 31 Spring Recess ",
    "url": "http://localhost:4000/calendar/#week-11",
    "relUrl": "/calendar/#week-11"
  },"14": {
    "doc": "Calendar",
    "title": "Week 12",
    "content": "Apr 3 Lecture 20: Kelly Betting HW 11 (due 04/11) . Apr 5 Lecture 21: AI Forecasting Pt. 1 Final Project Proposal instructions (due 04/12) Apr 7 Discussion 11 Discussion Worksheet ",
    "url": "http://localhost:4000/calendar/#week-12",
    "relUrl": "/calendar/#week-12"
  },"15": {
    "doc": "Calendar",
    "title": "Week 13",
    "content": "Apr 10 Lecture 22: AI Forecasting Pt. 2 HW 12 (due 4/18) Apr 13 Lecture 23: Forecasting Software Tools Slides April 15 Discussion 12 ",
    "url": "http://localhost:4000/calendar/#week-13",
    "relUrl": "/calendar/#week-13"
  },"16": {
    "doc": "Calendar",
    "title": "Week 14",
    "content": "Apr 18 Lecture 24: Avoiding Statistical Traps Slides Apr 20 Lecture 25: The Winner's Curse and Adverse Selection Notebook Apr 22 Discussion 13 ",
    "url": "http://localhost:4000/calendar/#week-14",
    "relUrl": "/calendar/#week-14"
  },"17": {
    "doc": "About",
    "title": "About",
    "content": " ",
    "url": "http://localhost:4000/",
    "relUrl": "/"
  },"18": {
    "doc": "About",
    "title": "Table of contents",
    "content": ". | About | Lecture | Office Hours | Grading | Course Staff | . ",
    "url": "http://localhost:4000/#table-of-contents",
    "relUrl": "/#table-of-contents"
  },"19": {
    "doc": "About",
    "title": "About",
    "content": "Forecasting has been used to predict elections, climate change, and the spread of COVID-19. Poor forecasts led to the 2008 financial crisis. In our daily lives, good forecasting ability can help us plan our work, be on time to events, and make informed career decisions. This practically-oriented class will provide you with tools to make good forecasts, including Fermi estimates, calibration training, base rates, scope sensitivity, and power laws. We'll discuss several historical instances of successful and unsuccessful forecasts, and practice making forecasts about our own lives, about current events, and about scientific progress. Prerequisites: Stat134 or a similar probability course (i.e. EECS126, STAT140, IEOR172). This is the website for the Spring 2023 iteration of the class. The website for the Spring 2022 version is here. ",
    "url": "http://localhost:4000/",
    "relUrl": "/"
  },"20": {
    "doc": "About",
    "title": "Lecture",
    "content": "MWF11-12, in Physics Building 251 . This class will be heavily disussion-based and participation will count towards the grade. Monday and Wednesday lectures will be a combination of traditional lecture and group activities, while most Fridays will be student-led small group discussions with instructors helping to facilitate. Instead of exams, there will be a final project. Students in Stat260 will be expected to do a more substantial project. There will be no official lab / discussion block, but some homework will involve programming. ",
    "url": "http://localhost:4000/#lecture",
    "relUrl": "/#lecture"
  },"21": {
    "doc": "About",
    "title": "Office Hours",
    "content": "Our office hour schedule this semester will be: . | Jacob Steinhardt (Lead Instructor): 325 Evans, Monday 10-11am | Jean-Stanislas Denain (GSI): 428 Evans, Friday 2:30-3:30pm (starting 1/27) | Meena Jagadeesan (GSI): 428 Evans, Tuesday 10-11am | Yongchan Wang (uGSI): 428 Evans, Wednesday 2-3pm | . ",
    "url": "http://localhost:4000/#office-hours",
    "relUrl": "/#office-hours"
  },"22": {
    "doc": "About",
    "title": "Grading",
    "content": "There will be a quiz at the beginning of class on most Fridays, which covers the reading from that week. It will generally be short (1-2 multiple-choice questions). The two quizzes where you got the lowest grade will be dropped. Grades will be based on a combination of: . | Homework (35%) | Discussion participation (15%) | Forecasting performance (20%) | Quizzes (10%) | Final project (20%) | . ",
    "url": "http://localhost:4000/#grading",
    "relUrl": "/#grading"
  },"23": {
    "doc": "About",
    "title": "Course Staff",
    "content": "To reach course staff, you can email forecasting-class-staff@lists.berkeley.edu. If possible, please avoid emailing professors or GSIs directly! . Jacob Steinhardt . Lead Instructor . (email) . Danny Hernandez . Instructor . (email) . Yan Zhang . Instructor . (email) . Jean-Stanislas Denain . GSI . (email) . Meena Jagadeesan . GSI . (email) . Yongchan Wang . uGSI . (email) . ",
    "url": "http://localhost:4000/#course-staff",
    "relUrl": "/#course-staff"
  },"24": {
    "doc": "Course Overview",
    "title": "Course Overview",
    "content": "Jacob Steinhardt . In this course we'll be teaching you the skills needed to be a successful forecaster. To help preview the course, here we'll outline what those skills are. When you first hear the word “forecasting”, you might first think of fancy statistical time series models, or fancy simulations such as climate or weather simulations. But actually, this course will cover very little of that. Those sorts of models can be useful when you have lots of data that is closely related to the prediction task, but in many real-world settings you have very limited data and instead have to rely on loosely analogous reference classes and your own world knowledge. The following set of analogies might help: . | Forecasting | Statistical Modeling | . | Estimation | Calculation | . | $n \\leq 10$ | $n \\geq 30$ | . Thus, forecasts have to rely on intuition, while informing that intuition with data, and training your intuition to become more accurate over time. Forecasts in this class will usually rely on three steps: forming a worldview, generating considerations, and combining these considerations into a calibrated probability distribution. I'll illustrate these with the example of forecasting how many confirmed Covid cases will be reported on Jan. 24th, 2022. In this example, the forecast was made as of Jan. 17th, 2022. | Forming a worldview: Before you can make reliable forecasts, you need some framework for thinking about the problem. This framework should identify the key moving pieces that could affect the answer and ideally point you towards the most relevant considerations. For instance, if you weren't already familiar with Covid and the trajectory of Covid cases, you would want to do enough reading to understand SEIR models, the idea of herd immunity, the fact that people often adjust their behavior in response to case numbers, and some knowledge of the logistics pipeline behind Covid tests (such as possible delays and capacity constraints). | Generating considerations: Once you have a worldview, you want to list considerations that are relevant to the answer. For Covid, this might include the current number of confirmed cases, your best guess of how quickly they are increasing/decreasing, and any ways that the actual number of confirmed cases might not track the actual number of cases (e.g. capacity constraints). | Combining considerations and evaluating uncertainty: Once you have a list of considerations and outcomes that you are happy with, you need to turn this into an actual forecast. We'll talk about this in detail later, but generally it involves using the list of considerations to rate the probability of each possible outcome. This involves some statistics but also involves a lot of intuition. | . Within these overarching steps, there are many individual skills that help you make better forecasts. For instance, while forecasts rely on intuition, people's intuitions don't usually map well onto probabilities, at least at first. Fortunately, it is possible to train your intuition to output accurate probabilities with just a few hours of “calibration training” (the subject of Friday's lecture). After this initial calibration training, the primary way in which forecasts are way off is not due to a statistics error, but due to missing a key consideration that affects the answer significantly (for instance, the number of reported Covid cases could be affected by a backlog, as seems to have been the case in SF in early January 2022). Therefore, a lot of this course will focus on skills for generating considerations and for not anchoring too much on a small set of possible outcomes. On the considerations front, this involves skills such as estimation, trend extrapolation, building good reference classes, and thinking about incentives. On the outcomes front, this involves combatting cognitive biases such as anchoring, and employing “pre-mortems” and other sanity checks. We also mentioned the importance of building an accurate worldview. For this, your “information diet” is important, and we'll discuss how to find good information sources and evaluate their trustworthiness. Based on these and other skills, we could expand the diagram above into something like the following (which is also a pretty good map of the topics in this class): . In summary, while forecasting uses statistics, it is much more far-reaching. You'll learn many skills that transfer beyond forecasting, such as how to evaluate information sources. And you'll find that forecasting can be used to improve decisions in your daily life. You'll get the most out of this class if you approach forecasting like a “sport” or other skilled activity, rather than as a set of facts to learn. We'll introduce helpful frameworks and ideas, but the best way to improve is through deliberate practice–making lots of forecasts, but also practicing the individual skills that go into them. We've built this class to help you succeed at that–each week you'll have a homework assignment that includes several forecasting questions, together with exercises to train the individual skills covered that week. We'll also devote each Friday to discussion with your peers, so that you can share what ideas worked well and learn from each other. To provide motivation, all the weekly forecasts will be part of a forecasting competition with a public leaderboard, which the instructors will also participate in. As far as we know, this is the first class of its kind offered anywhere in the world. You're part of an experiment, and you'll also be the first cohort of students to systematically train these skills over an extended period of time. Forecasting is a rapidly developing field and we think many of you could become leaders in this field if you choose to. ",
    "url": "http://localhost:4000/lectures/lec0-course-overview/#course-overview",
    "relUrl": "/lectures/lec0-course-overview/#course-overview"
  },"25": {
    "doc": "Course Overview",
    "title": "Course Overview",
    "content": " ",
    "url": "http://localhost:4000/lectures/lec0-course-overview/",
    "relUrl": "/lectures/lec0-course-overview/"
  },"26": {
    "doc": "Lecture 1 - Why Care About Forecasting?",
    "title": "Why Care About Forecasting?",
    "content": "Danny Hernandez and Frances Ding This post is a brief intro to forecasting. We will explain why we're teaching this class, and why we think Berkeley students should care about forecasting. ",
    "url": "http://localhost:4000/lectures/lec1-why-care-about-forecasting/#why-care-about-forecasting",
    "relUrl": "/lectures/lec1-why-care-about-forecasting/#why-care-about-forecasting"
  },"27": {
    "doc": "Lecture 1 - Why Care About Forecasting?",
    "title": "Everyone makes bets, and the bets matter a lot.",
    "content": "Some examples of bets that could come up in your own life are: . | Some of you will take some equity from a company, and therefore bet on the success of the company. The good bets are likely to be worth millions of dollars. | How likely is this relationship to last 20 years? Assuming it lasts, how likely am I to be extremely happy with it? | Many of you will do research and pursue scientific breakthroughs. Most of the value of research is in a handful of breakthroughs, and you have to choose research directions without knowing whether they will lead to a breakthrough. | How long will it take me to finish this homework? (Am I actually going to be able to make it to that thing I said I'd go to?) | . ",
    "url": "http://localhost:4000/lectures/lec1-why-care-about-forecasting/#everyone-makes-bets-and-the-bets-matter-a-lot",
    "relUrl": "/lectures/lec1-why-care-about-forecasting/#everyone-makes-bets-and-the-bets-matter-a-lot"
  },"28": {
    "doc": "Lecture 1 - Why Care About Forecasting?",
    "title": "What do we mean by forecasting",
    "content": "In this course we'll define forecasting as estimating a probability of observing a well defined outcome by some date. Some examples of well defined forecasts, along with how I arrived at the forecast: . | After looking at the scores from the Big Game for 2 minutes, I'd put a 60% chance on Berkeley winning the next game. | I think there's an 80% chance I'll finish writing this lecture in less than 6 hours of total work. So far I spent approximately 2 hours on it, I currently have a first draft with some feedback. I've given similar talks to about 6 different audiences. | The way I initially valued my equity for Twitch, a startup I joined in 2011, was that I put a 10% chance on Twitch being worth a billion dollars within 5 years. Twitch was valued at 10-20x less than that when I joined, and Instagram had recently been acquired for a billion dollars. | . From these examples, we see that most “bets” come down to one's (often implicit) forecasts. ",
    "url": "http://localhost:4000/lectures/lec1-why-care-about-forecasting/#what-do-we-mean-by-forecasting",
    "relUrl": "/lectures/lec1-why-care-about-forecasting/#what-do-we-mean-by-forecasting"
  },"29": {
    "doc": "Lecture 1 - Why Care About Forecasting?",
    "title": "Some bets, and their underlying forecasts, affect the world a lot",
    "content": "Here are some examples: . | The US government and the Gates foundation expected that there was a reasonably high chance vaccines would work against Covid-19 and be developed in time to make a difference. This forecast turned into action through guarantees to buy vaccines from manufacturers (even before FDA approval was given) and in offering funding to scale up manufacturing capacity. Investments on the order of billions probably paid off in trillions of dollars of public good. | Google, Amazon, Facebook, Stripe, and Bitcoin were bets by founders, staff, and investors. For many people with early involvement these bets returned more than all their previous and future bets combined, both financially and in terms of impact on the world. | Former President John F. Kennedy said that during the Cuban missile crisis, he thought there was as high as a 50% chance that the situation would escalate to a nuclear exchange. | . Hopefully these examples make it clear that forecasting accurately can have a huge impact on the world, which is half the motivation for this class. The other half is that, fortunately, forecasting ability can be improved; it's not a talent that you either have or don't have. ",
    "url": "http://localhost:4000/lectures/lec1-why-care-about-forecasting/#some-bets-and-their-underlying-forecasts-affect-the-world-a-lot",
    "relUrl": "/lectures/lec1-why-care-about-forecasting/#some-bets-and-their-underlying-forecasts-affect-the-world-a-lot"
  },"30": {
    "doc": "Lecture 1 - Why Care About Forecasting?",
    "title": "It's recently been shown that getting better at forecasting is tractable",
    "content": "Here is some of the evidence showing that forecasting skill can be improved: . | With a 1 hr training Phillip Tetlock, a professor at the University of Pennsylvania, improved participants' forecasts by 14% (relative to a control group) in a year-long geopolitical forecasting competition. Some examples of forecasts that were in the competition: What is the probability the U.S. will sign the Paris Accord?; Will the U.S. deploy ground troops in Syria?; etc. This research was mostly done in the last decade, so it's only been leveraged a modest amount. | One desirable property of forecasts is calibration. When someone is “calibrated”, that means the events they forecast with 90% probability really occur 9 times out of 10, and the events they forecast with 50% probability really occur half the time, and so on. Douglas Hubbard found that most people can become calibrated in about 2 hours of training. | . | By measuring forecasting performance and putting the most accurate forecasters together on teams, Tetlock was able to assemble teams that beat professional CIA analysts, who had access to classified intel. | . This shows that there is significant variation in forecasting skills beyond what can be conveyed during a 1-hour training session. In this class, we'll help impart those skills. With deliberate practice, we think many of you can reach the level of these elite forecasting teams. ",
    "url": "http://localhost:4000/lectures/lec1-why-care-about-forecasting/#its-recently-been-shown-that-getting-better-at-forecasting-is-tractable",
    "relUrl": "/lectures/lec1-why-care-about-forecasting/#its-recently-been-shown-that-getting-better-at-forecasting-is-tractable"
  },"31": {
    "doc": "Lecture 1 - Why Care About Forecasting?",
    "title": "Now let's practice a little.",
    "content": "(In class this will be a group activity.) . For each of the following questions we'll estimate an 80% confidence interval. This is an interval you think has an 80% chance of containing the true, known answer. Ideally, if we went through dozens of questions like this, 80% of the time your confidence interval would contain the right answer (importantly, you shouldn't aim for the confidence interval to have the right answer 100% of the time!). We're asking for a confidence interval and not just a point estimate because it will provide you with better feedback on how to improve forecasts than if you just gave a single number point estimate. | UC Berkeley surveyed English Majors graduating in 2020. | What is the fraction of graduates who responded seeking employment (having trouble finding a job)? | Among graduates who reported salaries, what was the average salary? | . | Austria's Organ Donation Rate is 99.98% (the policy is that by default, you consent to organ donation, but you can opt out). What is Germany's organ donation rate (the policy there is that you have to voluntarily opt in to donate)? | . We'll add the answers to this post after class. ",
    "url": "http://localhost:4000/lectures/lec1-why-care-about-forecasting/#now-lets-practice-a-little",
    "relUrl": "/lectures/lec1-why-care-about-forecasting/#now-lets-practice-a-little"
  },"32": {
    "doc": "Lecture 1 - Why Care About Forecasting?",
    "title": "Lecture 1 - Why Care About Forecasting?",
    "content": " ",
    "url": "http://localhost:4000/lectures/lec1-why-care-about-forecasting/",
    "relUrl": "/lectures/lec1-why-care-about-forecasting/"
  },"33": {
    "doc": "Lecture 10 - Common Probability Distributions",
    "title": "Lecture 10: Common Probability Distributions",
    "content": "When we output a forecast, we're either explicitly or implicitly outputting a probability distribution. For example, if we forecast the AQI in Berkeley tomorrow to be “around” 30, plus or minus 10, we implicitly mean some distribution that has most of its probability mass between 20 and 40. If we were forced to be explicit, we might say we have a normal distribution with mean 30 and standard deviation 10 in mind. There are many different types of probability distributions, so it's helpful to know what shapes distributions tend to have and what factors influence this. From your math and probability classes, you're probability used to the Gaussian or normal distribution as the “canonical” example of a probability distribution. However, in practice other distributions are much more common. While normal distributions do show up, it's more common to see distributions such as log-normal or power law distributions. In the remainder of these notes, I'll discuss each of these in turn. The following table summarizes these distributions, what typically causes them to occur, and several examples of data that follow the distribution: . | Distribution | Gaussian | Log-normal | Power Law | . | Causes | Independent additive factors | Independent multiplicative factors | Rich get richer, scale invariance | . | Tails | Thin tails | Heavy tails | Heavier tails | . | Examples | -heights | -US GDP in 2030 | -city population | . |   | -temperature | -price of Tesla stock in 2030 | -twitter followers | . |   | -measurement errors |   | -word frequencies | . ",
    "url": "http://localhost:4000/lectures/lec10-common-distributions/#lecture-10-common-probability-distributions",
    "relUrl": "/lectures/lec10-common-distributions/#lecture-10-common-probability-distributions"
  },"34": {
    "doc": "Lecture 10 - Common Probability Distributions",
    "title": "Normal Distribution",
    "content": "The normal (or Gaussian) distribution is the familiar “bell-shaped” curve seen in many textbooks. Its probability density is given by $p(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\Big(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\Big)$, where $\\mu$ is the mean and $\\sigma$ is the standard deviation. Normal distributions occurs when there are many independent factors that combine additively, and no single one of those factors “dominates” the sum. Mathematically, this intuition is formalized through the central limit theorem. Example 1: temperature. As one example, the temperature in a given city (at a given time of year) is normally distributed, since many factors (wind, ocean currents, cloud cover, pollution) affect it, mostly independently. Example 2: heights. Similarly, height is normally distributed, since many different genes have some effect on height, as do other factors such as childhood nutrition. However, for height we actually have to be careful, because there are two major factors that affect height significantly: age and sex. 12-year olds are (generally) shorter than 22-year-olds, and women are on average 5 inches (13cm) shorter than men. These overlaid histograms show heights of adults conditional on sex. Thus, if we try to approximate the distribution of heights of all adults with a normal distribution, we will get a pretty bad approximation. However, the distribution of male heights and female heights are separately well-approximated by normal distributions. | All | Males | Females | . | | | | . Example 3: measurement errors. Finally, the errors of a well-engineered system are often normally-distributed. One example would be a physical measurement apparatus (such as a voltmeter). Another would be the errors of a well-fit predictive model. For instance, when I was an undergraduate I fit a model to predict the pitch, yaw, roll, and other attributes of an autonomous airplane. The results are below, and all closely follow a normal distribution: . Why do well-engineered systems have normally-distributed errors? It's a sort of reverse central limit theorem: if they didn't, that would mean there was one large source of error that dominated the others, and a good engineer would have found and eliminated that source. Brainstorming exercise. What are some other examples of random variables that you expect to be normally distributed? . Caveat: normal distributions have thin tails. The normal distribution has very “thin” tails (falling faster than an exponential), and once we reach the extremes the tails usually underestimate the probability of rare events. As a result, we have to be careful when using a normal distribution for some of the examples above, such as heights. A normal distribution predicts that no women should be taller than 6'8”, yet there are many women who have reached this height (read more here). If we care specifically about the extremes, then instead of the normal distribution, a distribution with heavier tails (such as a t-distribution) may be a better fit. ",
    "url": "http://localhost:4000/lectures/lec10-common-distributions/#normal-distribution",
    "relUrl": "/lectures/lec10-common-distributions/#normal-distribution"
  },"35": {
    "doc": "Lecture 10 - Common Probability Distributions",
    "title": "Log-normal Distributions",
    "content": "While normal distributions arise from independent additive factors, log-normal distributions arise from independent multiplicative factors (which are often more common). A random variable $X$ is log-normally distributed if $\\log(X)$ follows a normal distribution–in other words, a log-normal distribution is what you get if you take a normal random variable and exponentiate it. Its density is given by . $p(x) = \\frac{1}{x\\sqrt{2\\pi\\sigma^2}} \\exp\\Big(-\\frac{(\\log(x) - \\mu)^2}{2\\sigma^2}\\Big)$. Here $\\mu$ and $\\sigma$ are the mean and variance of $\\log(X)$ (not $X$). | Examples of log-normal distributions | Log-normal(0, 1) compared to Normal(0, 1) | . | | | . Multiplicative factors tend to occur whenever there is a “growth” process over time. For instance: . | The number of employees of a company 5 years from now (or its stock price) | US GDP in 2030 | . Why should we think of factors affecting a company's employee count as multiplicative? Well, if a 20-person company does poorly it might decide to lay off 1 employee. If a 10,000-person company does poorly, it would have to lay off hundreds of employees to achieve the same relative effect. So, it makes more sense to think of “shocks” to a growth process as multiplicative rather than additive. Log-normal distributions are much more heavy-tailed than normal distributions. One way to get a sense of this is to compare heights to stock prices. |   | Height (among US adult males) | Stock price (among S&amp;P 500 companies) | . | Median | 175.7 cm | $119.24 | . | 99th percentile | 191.9 cm | $1870.44 | . To check if a variable X is log-normal distributed, we can plot a histogram of log(X) (or equivalently, plot the x-axis on a log scale), and this should be normally distributed. For example, consider the following plots of the Lognormal(0, 0.9) distribution: . | Standard axes | Log scale x-axis | . | | | . Brainstorming exercise. What are other quantities that are probably log-normally distributed? . ",
    "url": "http://localhost:4000/lectures/lec10-common-distributions/#log-normal-distributions",
    "relUrl": "/lectures/lec10-common-distributions/#log-normal-distributions"
  },"36": {
    "doc": "Lecture 10 - Common Probability Distributions",
    "title": "Power Law Distributions",
    "content": "Another common distribution is the power law distribution. Power law distributions are those that decrease at a rate of $x$ raised to some power: $p(x) = C / x^{\\alpha}$ for some constant $C$ and exponent $\\alpha$. (We also have to restrict $x$ away from zero, e.g. by only considering $x &gt; 1$ or some other threshold.) . Like a log-normal distribution, power laws are heavy-tailed. In fact, they are even heavier-tailed than log-normals. To identify a power law, we can create a log-log plot (plotting both the x and y-axes on log scales). Variables that follow power laws will show a linear trend, while log-normal variables will have curvature. Here we plot the same distributions as above, but with log scale x and y axes: . In practice, log-normal and power-law distributions often only differ far out in the tail and so it isn't always easy (or important) to tell the difference between them. What leads to power law distributions? Here are a few real-world examples of power law distributions (plotted on a log-log scale as above): . | Words in TV scipts | Words in the Simpsons | US city populations | . | | | | . The factors that lead to power law distributions are more varied than log-normals. For a good overview, I recommend this excellent paper by Michael Mitzenmacher. I will summarize two common factors below: . | One reason for power laws is that they are the unique set of scale-invariant laws: ones where $X$ and $2X$ (and $3X$) all have identical distributions. So, we should expect power laws in any case where the “units don't matter”. Examples include the net worth of individuals (dollars are an arbitrary unit) and the size of stars (meters are an arbitrary unit, and more fundamental physical units such as the Planck length don't generally affect stars). | Another common reason for power laws is preferential attachment or rich get richer phenomena. An example of this would be twitter followers: once you have a lot of twitter followers, they are more likely to retweet your posts, leading to even more twitter followers. And indeed, the distribution of twitter followers is power law distributed: . | . “Rich get richer” also explains why words are power law distributed: the more frequent a word is, the more salient it is in most people's minds, and hence the more it gets used in the future. And for cities, more people think of moving to Chicago (3rd largest city) than to Arlington, Texas (50th largest city) partly because Chicago is bigger. Brainstorming exercise. What are other instances where we should expect to see power laws, due to either scale invariance or rich get richer? . Exercise. Interestingly, in contrast to cities, country populations do not seem to fit a power law (although they could fit a mixture of two power laws reasonably): . Can you think of reasons that explain this? . There is much more to be said about power laws. In addition to the Mitzenmacher paper mentioned above, I recommend this blog post by Terry Tao. Concluding Exercise. Here are a couple examples of data you might want to model. For each, would you expect its distribution to be normal, log-normal, or power law? . | Incomes of US adults | Citations of papers | Number of Christmas trees sold each year | . ",
    "url": "http://localhost:4000/lectures/lec10-common-distributions/#power-law-distributions",
    "relUrl": "/lectures/lec10-common-distributions/#power-law-distributions"
  },"37": {
    "doc": "Lecture 10 - Common Probability Distributions",
    "title": "Lecture 10 - Common Probability Distributions",
    "content": " ",
    "url": "http://localhost:4000/lectures/lec10-common-distributions/",
    "relUrl": "/lectures/lec10-common-distributions/"
  },"38": {
    "doc": "Lecture 11 - Prioritizing Information",
    "title": "Lecture 11: Prioritizing Information",
    "content": "So far, we've focused on individual skills involved in a forecast: extrapolating trends, employing reference classes, how to combine estimates, and thinking about alternatives. Next I want to turn to integrating these, and other skills, when making complex forecasts. We'll consider the following question (worked through on Dec. 21st, note the Metaculus question closed Dec. 1st): . When will the UK's pre-March 2022 peak 7-day moving average of current COVID hospitalizations occur? . This question has many considerations and moving parts, and we'll need more than one lecture to get to all of them. For this lecture, I'll be focusing on the following skill: listing key considerations, ranking them by their importance and uncertainty, and following up to resolve the uncertainty. From this we'll end up with a rough point estimate, but not a full probability distribution. In the next lecture I'll focus on how to combine all the considerations together into a full probabilistic forecast. As usual, I'll include comments from Misha Yagudin (a top-ranked forecaster) in italics. And for reference, here are case counts in the UK and South Africa as of Dec. 21st: . ",
    "url": "http://localhost:4000/lectures/lec11-prioritizing-information/#lecture-11-prioritizing-information",
    "relUrl": "/lectures/lec11-prioritizing-information/#lecture-11-prioritizing-information"
  },"39": {
    "doc": "Lecture 11 - Prioritizing Information",
    "title": "Step 1: Listing Key Considerations",
    "content": "When approaching a complex forecasting question, it's useful to start by listing as many relevant considerations as you can think of. Here is the list I came up with for the UK Omicron question (ordered by when I thought of them, not by importance): . | Hospitalizations lag cases by ~9 days | The peak of the 7-day moving average will occur 3 days later than the single-day peak | Holidays or other mass gatherings could affect the peak | We can forecast by guessing max # of people infected together with Omicron doubling time and current case numbers. | Max # of people infected: Will the UK adopt dramatic NPIs to curb omicron, or do nothing? Or will people's individual precautions slow the curve? (Note: I generated the 3rd option by thinking about “other” options.) . | NPIs: max # infected roughly equal to hospital capacity | Do nothing: max # infected roughly equal to herd immunity | Slow the curve: trickier, something in between | . | Omicron doubling time: ~4 days? | Current case numbers: no clue, can probably estimate from known data | Seasonality effects probably important | What are UK leader's current stance towards NPIs? | “Other” option brainstorming: What if hospitals are at capacity for an extended period of time and so there's no clear “peak”? | . Brainstorming exercise. Are there other key considerations not on this list? . ",
    "url": "http://localhost:4000/lectures/lec11-prioritizing-information/#step-1-listing-key-considerations",
    "relUrl": "/lectures/lec11-prioritizing-information/#step-1-listing-key-considerations"
  },"40": {
    "doc": "Lecture 11 - Prioritizing Information",
    "title": "Step 2: Prioritizing Considerations",
    "content": "Once you have a list of key considerations, it's helpful to rate each one by how important it is, and how uncertain you are. This way you can focus follow-up research on questions with both high importance and high uncertainty. I listed my rating of this for the UK Omicron question below: . | Consideration | Importance | Uncertainty | . | Hospital lag | High | Low (fairly sure it's 7-11 days) | . | 7-day lag | Medium | Very low | . | Holidays | Medium (xmas and ny important but likely before peak) | Medium (don't know much about UK holidays) | . | strong NPIs or no | High | High | . | Omicron doubling time | High | Medium (2-5 days?) | . | Current cases | High | High | . | Seasonality | High | High (use last year as reference class, know it peaks in January but not sure exactly when) | . | UK leader stance | Medium-Low (could easily change) | High | . | Extended peak | Medium (short generation interval makes this unlikely) | Medium | . Exercise. Do you agree with the above ratings? For any considerations you generated, how would you rank their importance and uncertainty? . Based on the above list, there's three considerations with high importance and high uncertainty: whether the UK adopts strong NPIs, current case counts, and how seasonality is likely to affect the peak. There's also one consideration with high importance and medium uncertainty: omicron doubling time. The next section of this post will focus on reducing each piece of uncertainty, using the tools we've developed in previous lectures. Misha: I myself would probably spend more time looking into “how did the last peaks go.” Primarily to have a better world model and be less confused about the issue. ",
    "url": "http://localhost:4000/lectures/lec11-prioritizing-information/#step-2-prioritizing-considerations",
    "relUrl": "/lectures/lec11-prioritizing-information/#step-2-prioritizing-considerations"
  },"41": {
    "doc": "Lecture 11 - Prioritizing Information",
    "title": "Step 3: Reducing Uncertainty",
    "content": "Strong NPIs or not . Thinking about this more, the relevant question is actually Will the number of Omicron cases be more closely dictated by hospital capacity or by herd immunity? This is because our strategy is to forecast the peak in terms of the doubling time and max number of cases, so the case maximum is the decision-relevant quantity. Let's first Fermi estimate how many people would need to get infected to reach (1) herd immunity or (2) hospital capacity. Note the UK has 68 million people in it. Herd immunity (Fermi). Suppose we reach herd immunity when 70% of people have either gotten Omicron or are immune. We'll first calculate existing levels of immunity: . | 30% of UK is doubly-vaccinated (but not triply). Each double-vaxxed person is ~40% (? rough guess, had trouble finding number) immune from Omicron. | 40% of UK is triply-vaccinated. Each such person is ~70% (?) immune from Omicron. | 15% of UK has gotten previous strain via confirmed case, would guess more like 30%-40% accounting for undertesting. Some overlap with vaccinated populations, but let's say this adds another 15% of people who are 25% immune. | . This leads to 0.3 * 0.4 + 0.4 * 0.7 + 0.15 * 0.25 = 44% currently immune. So herd immunity implies another 25% or 17 million people getting Omicron. Hospital capacity (Fermi). The UK has 100,000 acute hospital beds (looked up on Google). People stay in hospital for about a week, so max hospital load governed by peak cases in ~1 week. Would guess hospitalization rate is 1-2% (was 4% for original strain, should be lower now because of vaccinations + prior infection + slightly lower severity, but Omicron infections will skew towards unvaccinated and vaccine effectiveness is waning). If we go with 1.5%, then 6.7 million infected would reach hospital capacity. (In reality less than that because some beds needed for other purposes, but there will also be additional infections in the weeks before/after.) . Hospital capacity (reference class). We can alternately use the UK's previous January wave as a reference class. The UK had 40,000 patients in the hospital at the last peak (looked up on OurWorldInData), with 60,000 confirmed cases/day and 2.4 million cumulative confirmed cases over the course of the wave. I'd guess the UK lets 2-3x as many people get sick in this wave before taking drastic action, due to a combination of (1) lower severity, (2) faster growth takes policymakers more by surprise, and (3) fatigue around NPIs. Also, if last January was a good reference class then going more than 5x would surely overwhelm hospitals. If we take 2.5x as our point estimate, this leads to 6 million infected. Conclusion. Both hospital capacity estimates suggest around 6-7 million cases. Herd immunity would seem to require exceeding hospital capacity by a factor of 3, which seems possible but unlikely. My takeaway is a point estimate of 6.7 million and a 70% confidence interval of [2.4 million, 13 million]. Seasonality . We know from experience that Covid tends to peak in the winter, due to a combination of holiday celebrations and people being inside more. This is a good use case for reference class forecasting, where we can look at seasonal effects in various countries last year: . The peaks were: Jan. 8 (US), Jan. 9 (Canada), Jan. 9 (UK), Jan. 26 (Spain), Dec. 23/Jan. 9 (Germany), Nov. 13/Jan. 10 (Austria), after January / not super clear (France). This generally suggests sometime near Jan. 9 with a possibility for significantly later (Spain) / something weird (France). Let's also consider hospitalizations: . The peaks were Jan. 5 (Netherlands), Jan. 12 (Canada), Jan. 14 (US), Jan. 18 (UK), Feb. 1 (Spain), no clear peak / pre-December peak (France, Italy, Belgium, Austria). These graphs were a bit weirder than the graphs of cases, although I'd still be somewhat surprised if the UK didn't have some sort of clear peak (even if it's an extended peak) in late December / early January. Conclusion. Overall, I think seasonality would point towards a peak in mid-January. Current Cases . Based on OurWorldInData, the UK had 83,000 confirmed cases on Dec. 20th: . Based on the pre-Omicron counts, it looks like at most 45,000 of those would have been from Delta. If I try to add up over all the days (subtracting off ~45,000/day for Delta), I get around 200,000 Omicron cases so far. Omicron Doubling Time . Let's start with Google: . That suggests 1.5-3 days, but I'm not prepared to take this on face value because (1) news has an incentive to sensationalize, and (2) initial doubling time has tended to slow down in past waves. Let me try a few more sources. I googled “omicron doubling time Eric Topol” (since Eric is one of my more trusted sources) and got this graph from one of his tweet threads: . This graph says 1.2 days but thinks Delta had a doubling time of 1.5 days, which didn't match my experience. Eric's recent op-ed says “2-3 days”. So perhaps 2.5? . Trevor Bedford actually shows his work and says 2.3-3.3 days. Says UK is currently at 2.3 days doubling time. Should I expect this doubling time to hold into the future? On the one hand, higher precautions = slower doubling; on the other hand, Christmas celebrations = faster doubling. I'm not sure which will win out so let's use last year in the UK as a reference class. I'll start at 250 cases and go up by factors of $\\sqrt{2}$ (a “half-doubling”): . | Dec. 11: 250 cases/million | Dec. 18: 352 cases/million (7 days to half-double) | Dec. 24: 500 cases/million (6 days to half-double) | Jan. 2: 720 cases/million (8.5 days to half-double) | . Conclusion. Looks like there was a slight slow-down but it was roughly constant. I'll make a slight upward adjustment and go with 2.4 days doubling time, with 70% uncertainty in range of [2, 3.3]. ",
    "url": "http://localhost:4000/lectures/lec11-prioritizing-information/#step-3-reducing-uncertainty",
    "relUrl": "/lectures/lec11-prioritizing-information/#step-3-reducing-uncertainty"
  },"42": {
    "doc": "Lecture 11 - Prioritizing Information",
    "title": "Putting it All Together",
    "content": "To integrate the information above, let's assume that the UK gets N Omicron cases total, currently has $N_0$ Omicron cases, and that the doubling time is t days. Assuming that $N/2$ of the cases occur before the peak, the peak will occur $\\log_2(N/2N_0) \\cdot t$ days from now. Based on the previous sections, I estimate: . | $N = 6.7 \\times 10^6$ | $t = 2.4$ | $N_0 = 0.2 \\times 10^6$ | . Plugging into the formula: $\\log_2(N/2N_0) \\cdot t = 4.066 \\cdot 2.4 = 9.8$ days from now. That says that cases will peak in 10 days (Dec. 31st). Add 9 days for hospitalizations and 3 days for the moving average, and we get an estimate of Jan. 12th. Note in comparison that the seasonality estimate would have predicted a slightly later peak, perhaps around Jan. 15th. I do think seasonality should matter, but not as much as the faster dynamics of Omicron. I decided to average these dates together in a 2:1 ratio to get a final estimate of Jan. 13th. ",
    "url": "http://localhost:4000/lectures/lec11-prioritizing-information/#putting-it-all-together",
    "relUrl": "/lectures/lec11-prioritizing-information/#putting-it-all-together"
  },"43": {
    "doc": "Lecture 11 - Prioritizing Information",
    "title": "What's Next",
    "content": "So far we've resolved our highest-priority sources of uncertainty and constructed a reasonable point estimate. But to generate a complete forecast (i.e. a probability distribution over outcomes), we need to assess the uncertainty of our estimate as well. We'll address this in the next lecture, where we examine: . | What assumptions are most likely to affect the estimate significantly. | Which numerical quantities our final estimate is most sensitive to. | . ",
    "url": "http://localhost:4000/lectures/lec11-prioritizing-information/#whats-next",
    "relUrl": "/lectures/lec11-prioritizing-information/#whats-next"
  },"44": {
    "doc": "Lecture 11 - Prioritizing Information",
    "title": "Additional Selected Comments",
    "content": "Misha sent the following general comments: . Some meta issues are being clear on . | Why do you need this answer? | What precision do you want? | . These are needed to prioritize effectively: . For example, if you are trying to get the best possible estimate, you'd need to think a lot and go into all details about sensitivities and what fraction of hospital capacity was used last time. If you are fine with an answer within a week or so, you can afford to reserve 2 or even 3 “doublings” for errors in your Fermi estimates. That's a lot and allows you to forget about specificity. He also notes: . You probably should be worried about model misspecification. You settled on a nice, clean method for estimating the peak of the next wave. From eyeballing their plot, Delta peaked thrice in the UK — could the second/third peak be higher than the first one for Omicron? . ",
    "url": "http://localhost:4000/lectures/lec11-prioritizing-information/#additional-selected-comments",
    "relUrl": "/lectures/lec11-prioritizing-information/#additional-selected-comments"
  },"45": {
    "doc": "Lecture 11 - Prioritizing Information",
    "title": "Lecture 11 - Prioritizing Information",
    "content": " ",
    "url": "http://localhost:4000/lectures/lec11-prioritizing-information/",
    "relUrl": "/lectures/lec11-prioritizing-information/"
  },"46": {
    "doc": "Lecture 12 - Turning Considerations Into Probabilities",
    "title": "Lecture 12: Turning Considerations Into Probabilities",
    "content": "The previous post started forecasting the UK hospital peak (based on information through Dec. 21, 2021). We generated several considerations and ultimately focused on the Omicron doubling time, the peak number of cases, the current number of Omicron cases, and the seasonality. In addition to a reference class forecast based on seasonality, we assumed the case peak would be roughly governed by hospital capacity and used the calculation: . DateOfPeak = Dec. 21     + 10 days to reach case peak (2.4-day doubling time and 4.1 doublings)     + 9 days (case peak to hospital peak)     + 3 days (lag of 7-day average)     = Jan. 12th . In this lecture we'll focus on going from this point estimate to a full probability distribution. This will involve two steps: . | Asking “what invalidating considerations could cause this forecast to be totally wrong”? | Asking “which numerical quantities is my forecast most sensitive to, and how uncertain am I about them?” | . The motivation for this is that most uncertainty is from either your entire estimate being structurally wrong (invalidating considertions), or from the specific numbers going into your estimate being inaccurate (numerical sensitivity). In many (most?) cases, the first form of uncertainty dominates, so it's good to check both. We'll work through both steps, then combine them into a final uncertainty estimate. At the end I've also included a Q&amp;A with Misha Yagudin on how this approach compares with his approach to forecasting. ",
    "url": "http://localhost:4000/lectures/lec12-considerations-probabilities/#lecture-12-turning-considerations-into-probabilities",
    "relUrl": "/lectures/lec12-considerations-probabilities/#lecture-12-turning-considerations-into-probabilities"
  },"47": {
    "doc": "Lecture 12 - Turning Considerations Into Probabilities",
    "title": "Part 1: Invalidating Considerations",
    "content": "I did the brainstorming exercise of “If the previous estimate is totally off, why is that?” I recommend that you try this exercise as well before reading what I came up with. (whitespace to avoid spoilers) . … . … . … . Okay, here's what I came up with: . | If the UK cases are capped by herd immunity rather than hospital strain (17+ million cases instead of 6.7 million) | If the doubling time is actually 1.5 days (vs. 2.4 days), as suggested in some articles | If the peak happens due to people self-adjusting their behavior to make $R$ barely less than $1$, leading to a very long “peak”. | . Let's see how much each of these could affect the answer. Consideration 1: herd immunity. This would add at most 2 more doublings, or ~5 days, to the date of the peak. Consideration 2: short doubling time. Since we assumed around 4 doublings before, this would subtract only ~4 days from the date of the peak. Consideration 3: extended peak. We calculated before that hospital capacity would correspond to around 6 million confirmed cases/week. Herd immunity was around 17 million cases, so this would mean 3 weeks to reach herd immunity. But I now realize that this is confirmed cases, and undertesting is around a factor of 2. So I think this would only really add 1.5 weeks, or ~9 days, unless people adjust their behavior to stay significantly below hospital capacity. I'll add another 3 days of wiggle room (12 days total) in case the extended peak is at 75% of hospital capacity rather than 100% of capacity, or in case I underestimated the herd immunity threshold. If I consider how subjectively surprised I would feel in each of the 3 worlds above, and turn that into probabilities, I get: 15% (herd immunity), 15% (short doubling time), 10% (extended peak). Exercise. Do you agree with the above probabilities? . Brainstorming exercise. What other considerations am I missing? . ",
    "url": "http://localhost:4000/lectures/lec12-considerations-probabilities/#part-1-invalidating-considerations",
    "relUrl": "/lectures/lec12-considerations-probabilities/#part-1-invalidating-considerations"
  },"48": {
    "doc": "Lecture 12 - Turning Considerations Into Probabilities",
    "title": "Part 2: Numerical Sensitivity",
    "content": "Next I checked the numerical sensitivity of the mainline forecast. Our mainline forecast is based on several quantities: . | The current number of UK Omicron cases, estimated at $N_0 = 200,000$ | The total number of future Omicron cases, estimated at $N = 6,700,000$. | The Omicron doubling time, estimated at $t = 2.4$ days | The lag $\\Delta_0$ between case peak and hospital peak, estimated at 9 days. | The lag $\\Delta_1$ between single-day hospital peak and 7-day average hospital peak, estimated at 3 days. | . Our formula for the number of days until the peak is then . $\\log_2(N/2N_0) \\cdot t + \\Delta_0 + \\Delta_1$ . Let's assess the sensitivity of this formula to each consideration: . | If $N$ or $N_0$ is off by a factor of $2$, then our answer changes by $2.4$ days. | If $t$ is $3.3$ instead of $2.4$, our answer changes by $3.7$ days. | If $\\Delta_0$ or $\\Delta_1$ is off by $1$, our answer changes by $1$ day. | . To make this more quantitative I put it into table form, including my $70\\\\%$ uncertainty intervals for each number: . | Parameter | Point estimate | Range | Effect on answer | . | $N_0$ | $0.2 \\times 10^6$ | $[0.15, 0.25] \\times 10^6$ | $[-0.8, +1.0]$ | . | $N$ | $6.7 \\times 10^6$ | $[5, 13] \\times 10^6$ | $[-1.0, +2.3]$ | . | $t$ | $2.4$ | $[2.0, 3.3]$ | $[-1.6, +3.7]$ | . | $\\Delta_0 + \\Delta_1$ | $12$ | $[9, 14]$ | $[-3, +2]$ | . Considering that probably not all errors will occur in the same direction, when I combine these errors together I subjectively end up with a 70% confidence interval of $[-3.6, +4.9]$ relative to the Jan. 12th point estimate. (I estimated these as e.g. $3.6 = \\sqrt{0.8^2 + 1.0^2 + 1.6^2 + 9^2}$ based on the premise that variances add for independent quantities. I don't think this is a logically valid calculation but it gives a decent ballpark, and the final numbers also seemed reasonable to me.) . Misha: I generally got a sense that your ranges are a bit too narrow, e.g., for doubling time. Metaculus is super uncertain about R_0 (their 70% CI 5.2 to 11.9), and “average” doubling guesstimates should probably be pretty uncertain given conflicting info, the impact of the holidays, impact of public concern, and government action. [Followed by some additional comments on why $N_0$ and $N$ should have higher uncertainty.] . I asked Misha if he also thought my final uncertainty estimates (given in the next section) were too small. He said: . Misha: Nope, I think they are fine (because the additional 45% went to extreme outcomes). ",
    "url": "http://localhost:4000/lectures/lec12-considerations-probabilities/#part-2-numerical-sensitivity",
    "relUrl": "/lectures/lec12-considerations-probabilities/#part-2-numerical-sensitivity"
  },"49": {
    "doc": "Lecture 12 - Turning Considerations Into Probabilities",
    "title": "Putting it Together",
    "content": "If we assume the mainline estimate is structurally correct and all errors are due to numerical sensitivity, then we end up with a 70% confidence interval of (rounded to whole numbers) Jan. 8th to Jan. 17th. That means there is a 15% chance of being earlier than Jan. 8th and of being later than Jan. 17th. If we instead consider structural uncertainty, we get a 15% chance of +5 days (Jan. 17th), a 15% chance of -4 days (Jan. 8th), and a 10% chance of +12 days (Jan. 24th). In reality, both forms of uncertainty are present. Overall, the uncertainty also skews a bit more towards later dates than earlier dates. If I subjectively combine this, I would put my overall forecast as follows: . | Median of Jan. 13th | 10% chance of Jan. 24th or later | 25% chance of Jan. 18th or later | 25% chance of Jan. 7th or earlier | . Exercise. Do you agree with this assessment? . ",
    "url": "http://localhost:4000/lectures/lec12-considerations-probabilities/#putting-it-together",
    "relUrl": "/lectures/lec12-considerations-probabilities/#putting-it-together"
  },"50": {
    "doc": "Lecture 12 - Turning Considerations Into Probabilities",
    "title": "Concluding Q&amp;A",
    "content": "Since this is the first lecture that presents a fully integrated forecasting method, I asked Misha how close it matches his approach to forecasting. Jacob: How closely does the method discussed in this and the previous lecture map onto your own approach to forecasting? I.e.: generate and prioritize considerations, reduce uncertainty, construct a mainline estimate (or multiple mainline estimates), consider numerical sensitivity + structural uncertainty. Misha: Well, I do all of the things from time to time. I do not do this explicitly in a step-by-step way. It's more of playing it by ear and attending to whatever feels most informative. The core step, which is missing from your writeups, is getting less confused about what's going on and assembling a world model. I usually start pretty cluelessly; for example, I was forecasting cultured meat progress last month. I spend a lot of time trying to understand how the processes might work, how to reference class might look like, and what technological limitations are. Until I had some understanding (still limited), I wasn't looking for considerations. But after building a world model, I developed ways to approach most questions (sometimes very structurally uncertain). To me, the key insight in your writeup was to look at beds/herd immunity and doubling. Everything else seems more like technical details necessary for delivering a good forecast but not primarily to the process. Jacob: Would you still consider [this lecture] good pedagogy for students? . Misha: I think it is a textbook example, looks good to me. I think it's put a bit too much weight on legible steps and a bit less on “actual creative work.” To be clear, these legible technical steps are important and worth having in front of you. My takeaway is that the approach above is useful and valuable, but that it is also important to build a good world-model (especially when confronting a new domain). We'll hopefully have more to say about that in upcoming lectures. ",
    "url": "http://localhost:4000/lectures/lec12-considerations-probabilities/#concluding-qa",
    "relUrl": "/lectures/lec12-considerations-probabilities/#concluding-qa"
  },"51": {
    "doc": "Lecture 12 - Turning Considerations Into Probabilities",
    "title": "Lecture 12 - Turning Considerations Into Probabilities",
    "content": " ",
    "url": "http://localhost:4000/lectures/lec12-considerations-probabilities/",
    "relUrl": "/lectures/lec12-considerations-probabilities/"
  },"52": {
    "doc": "Lecture 3 - Scoring Rules",
    "title": "Lecture 3: Scoring Rules",
    "content": "Yan Zhang and Frances Ding . We want to get better at predicting things, so the following question is very fundamental: . How do we reward people for giving us better predictions? . Let's start by thinking about how we might make a rule for this when there are 2 outcomes. For a natural first draft, we can just have you bet 1 unit of score at even odds. This means if you bet correctly on the desired outcome you will gain 1 point, and if you were wrong you will lose 1 point. For example, you can guess “the temperature tomorrow morning at 6AM will not be between 60 and 70 degrees.” If the temperature at 6AM ends up being 56 degrees, you will get 1 point. Over time, it's clear that people who do well at this will in general score more in the long run. However, there's a way in which this rule fails to let people show their skills. For example, suppose for every single event with an actual probability of 60%, you are perfectly calibrated and know this, but Jean always thinks the probability is 100%. Under our naive draft, you two will always bet the same way, “yes”, in these events, but the relative skill between you will never be discovered. This gives rise to our first main idea - we need to show the distribution of a prediction, not just a single number. So… draft 2! You bet on something like “it will snow tomorrow” by giving a probability $p$. Then, you get $p$ points if the event occurs. (so if you bet “90%”, then you get 0.9 points if it snows and 0.1 otherwise). This is better than the first draft since you are offering more information about your beliefs, but it has a very interesting flaw. So take a couple of minutes to think about this: . The answer is that if you think there's a 60% chance that it will snow, your optimal strategy is to actually bet 100%! This means while our draft 2 lets people show their skills, it also incentivizes them to hide their skills by betting something that doesn't represent what they actually think. While this is interesting from a game and psychology perspective, in the context where we are trying to see how to predict things better and/or get some information from what people are actually betting, we want to extract people's true beliefs about things. To mathematically formalize the things we wanted up to this point: . | Assume we have a finite number of outcomes $1, \\ldots n$ in our sample space. | Our predictions should be distributions. That is, an assignment of $q_i$ to each $i$ so that they add up to 1. Let's call such a prediction $q$. | We want a scoring rule; that is, a way to assign points on what actually happened. We can call this rule $f(q, i)$. | We want a strictly proper scoring rule; that is, if you think the reality of the world is $(q_1, … q_n)$, then your prediction $q$ should actually be equal to $(q_1, … q_n)$ to maximize your expected score. | . ",
    "url": "http://localhost:4000/lectures/lec3-scoring-rules/#lecture-3-scoring-rules",
    "relUrl": "/lectures/lec3-scoring-rules/#lecture-3-scoring-rules"
  },"53": {
    "doc": "Lecture 3 - Scoring Rules",
    "title": "Strictly proper scoring rules",
    "content": "So what's a good example of a strictly proper scoring rule? If you are only going to remember one, that would be Good's logarithmic scoring rule. This is defined by $(f(q, i) = \\log(q_i)$, where we are using the natural log. | As an example, suppose you bet that tomorrow it will rain with probability 20%, snow with probability 30%, and neither rain nor snow with probability 50%, then when it snows you will be “rewarded” $\\log(0.3)$, which is roughly -1.2 points. | It might be weird to think of negative points as a reward, but you should see that you are getting something “less negative” than someone who assigned probability 10% to snowing, which would give them -2.3 points. | In machine learning, the logarithmic scoring rule often appears in the guise of the log loss. | . There are (infinitely!) many other strictly proper scoring rules, and a good second one to know is Brier's quadratic scoring rule. This rule assigns $[f(q, i) = -\\sum_{j=1}^n (q_j - o_{ij})^2,]$ where $o_{ij} = 1$ if $i=j$ and $0$ otherwise. A few interesting things about this rule: . | It helps to do some algebra and simplify it. If you open the parentheses, you get $2q_i - 1 - \\sum_{j=1}^n q_j^2$. One interpretation of this is that it fixes our naive (remember draft 2?) scoring rule of $q_i$ to have a “quadratic punishment” that disincentivizes to pushing the prediction all the way to 1 or 0. | You can think of this as the negative of the mean-squared error, which comes up often in statistics as a way of measuring “badness.” Note that the mean-squared error metric is also called the Brier score, which can be easily confused with Brier's quadratic scoring rule. They are just negatives of each other, so you want a low Brier score (since it measures error) but a high scoring rule outcome. | . There are pros and cons for both rules. For example, the logarithmic rule is more sensitive at small probabilities than the quadratic rule, which could be either good or bad depending on what you want to reward the forecaster for. Besides these concerns, it is always good to keep in mind that being strictly proper is not the be-all and end-all; there might be plenty of reasons to pick scoring rules that are “almost proper” but achieve other goals, such as being more intuitive for forecasters, having positivity and negativity be meaningful (for example, as stated all log scores are negative!), etc. See Greenberg's paper for some ideas in this direction. ",
    "url": "http://localhost:4000/lectures/lec3-scoring-rules/#strictly-proper-scoring-rules",
    "relUrl": "/lectures/lec3-scoring-rules/#strictly-proper-scoring-rules"
  },"54": {
    "doc": "Lecture 3 - Scoring Rules",
    "title": "Prediction Markets and Platforms",
    "content": "Remember that our original goal was to reward people for making better predictions. A natural way to do this is to set up structures such as games and/or contests that reflect better predictive abilities. There are two major categories of such structures. The first such category is called prediction markets. While this word is itself ambiguous, it typically means (such as in Wikipedia) classical financial markets where you buy or sell abstract objects that reflect your belief in an event that will resolve in the future. | For example, on Predictit, one of the more popular prediction markets, you buy and sell “shares” of an event taking place. The price of the share will always be between 1 and 99 cents, which corresponds to what the market thinks the probability percentage of an event taking place is. For an outcome such as “it will snow tomorrow by 12PM PT”, you can buy “yes” shares when the price is too low (which drives up the price) or buy “no” shares when the price is too high (which drives down the price). When the market closes (the event resolves) successfully, if the event happened, then “yes” shares are now worth $1 and “No” shares become worthless, and the opposite happens if the event did not happen. | Sports betting is a pretty big industry (e.g. Betfair) working under similar structures. People frequently say things such as “the market thinks X” by interpreting the market state as a kind of prediction. For academics, another quite exciting prediction market of this type is the Iowa Electronic Markets, which has been a source of interesting research about the power of prediction markets. | . An example Predictit market from Jan. 14, 2022 showing the latest prices for “yes” and “no” shares. The second such category is something we call prediction platforms, where instead of trading, you enter predictions like how you would submit a structured answer to some sort of online exam, and then you get points based on a… (usually trying to be strictly proper) scoring rule! . | For example, on Metaculus, one of the more popular prediction platforms, you put in a probability of how likely you think an event will happen. You can also revise your estimates as time progresses, until the point when the question “closes” (usually after the event happens or after a certain amount of time has passed). Afterwards, your guesses are scored with a fairly complicated proper scoring rule that, at heart, is the logarithmic scoring rule, with some adjustments on top for rewarding you when you are “more right” than the rest of the community. There are also different scoring rules that are used for other types of questions, such as predicting a number versus a probability, or prediction tournaments. | Confusingly, sometimes “prediction markets” also refer to prediction platforms which use scoring rules as a basis, such as Robin Hanson's “markets” made from scoring rules (in particular, this paper shows that the logarithmic scoring rule was the only rule to satisfy some nice properties such a market would want to enjoy). | . While the second type, prediction platforms, may end up being more directly relevant to our class, prediction markets are a good way to get priors and learn about what people think about some particular subject. We hope your predictive skills will be sharpened by interactions with both predictive markets and platforms! . (Thanks to Frances Ding, Alex Wei and Eric Neyman for help preparing this post. I also learned from and recommend Tim Roughgarden's computer science-oriented lecture notes) . ",
    "url": "http://localhost:4000/lectures/lec3-scoring-rules/#prediction-markets-and-platforms",
    "relUrl": "/lectures/lec3-scoring-rules/#prediction-markets-and-platforms"
  },"55": {
    "doc": "Lecture 3 - Scoring Rules",
    "title": "Mathematical Tangent",
    "content": "Here's a really nice way (h/t Eric Neyman) to see how the log and quadratic rules naturally appear, if we aren't afraid to do a bit of calculus. Let's consider our goal of finding a proper scoring function in a simplified case with just 2 outcomes (so $p_1 = p, p_2 = (1-p)$), which is to find a scoring function $f$ such that $p f(x) + (1-p) f(1-x)$ is maximized at $x=p$. Taking the derivative with respect to $x$ and setting equal to 0, we get $pf'(p) - (1-p)f'(1-p) = 0$, or $pf'(p) = (1-p)f'(1-p)$. Now, let's turn the question around and ask our “wishful thinking” selves: what $f'()$ would make this work? . | A natural choice is $f'(p) = (1-p)$, because then the left and right hand sides are both $p(1-p)$. | Another natural choice is $f'(p) = 1/p$, because then the left and right hand sides are both 1. | . I leave the rest to you to see that these two options exactly correspond to the quadratic and log rules, respectively! . ",
    "url": "http://localhost:4000/lectures/lec3-scoring-rules/#mathematical-tangent",
    "relUrl": "/lectures/lec3-scoring-rules/#mathematical-tangent"
  },"56": {
    "doc": "Lecture 3 - Scoring Rules",
    "title": "Lecture 3 - Scoring Rules",
    "content": " ",
    "url": "http://localhost:4000/lectures/lec3-scoring-rules/",
    "relUrl": "/lectures/lec3-scoring-rules/"
  },"57": {
    "doc": "Lecture 4 - Estimation 101",
    "title": "Lecture 4: Estimation 101",
    "content": "Yan Zhang and Frances Ding . Forecasting, like any other quantitative activity, involves putting numbers down at some point. Often, getting the exact numbers isn't too important, but it's important to get a number “decent” enough to get a good grasp of the situation. This is the skill of estimation. For example, suppose we are forecasting something involving the population density of the US, either soon or in 100 years. | To get the population density, by definition we need the number of people divided by the geographical area. This means we need both of these numbers. Let's start with the geographical area. | To get the geographical area, one way to get there is having the (inexact, because it's an estimation) model that the US is basically a rectangle. This means we can estimate its area by having numbers for its width and height. | To get the width of the US… | . This train of thought leads nicely to our first warmup: . ",
    "url": "http://localhost:4000/lectures/lec4-estimation/#lecture-4-estimation-101",
    "relUrl": "/lectures/lec4-estimation/#lecture-4-estimation-101"
  },"58": {
    "doc": "Lecture 4 - Estimation 101",
    "title": "A Warmup",
    "content": "What is the width of the US? Some of you might just already have this number in your head. If you didn't know it, however, we have to put down some number. As you might guess from the title of the class, we are about to teach you the best way to put a number down that you don't know. This is, of course, to Google the number. A quick google gives that it is about 2800 miles. Okay, so that's not actually the point of this class, which is to teach you how to estimate things in your head instead of asking Google. For me, the two best reasons for doing this are: . | To be able to figure out things that are hard to look up. Many things have actual numbers but nobody bothers to have an exact count (e.g. how many people in the U.S. are on the Keto diet right now), especially if it comes from your personal life (e.g. how many hours you spend a day on daydreaming). It's also important to bear in mind that many “official” sounding numbers (width of the US, say) are themselves obtained from estimation. | To “stay in shape” with quantitative skills. Estimation is kind of like arithmetic, weight training, or being able to fix things yourself. We can use calculators to do calculations faster, use trolleys to carry things, or send things into a tech repair store, but there is obviously a lot of value in learning to at least do some things “by hand.” | . ",
    "url": "http://localhost:4000/lectures/lec4-estimation/#a-warmup",
    "relUrl": "/lectures/lec4-estimation/#a-warmup"
  },"59": {
    "doc": "Lecture 4 - Estimation 101",
    "title": "A Second Warmup",
    "content": "How many people live in Iceland? Here are a few things you might try. Note that what you would try in practice depends on what you already know! . | You know Iceland is a “small European country.” You know it's smaller than Germany, and you happen to know that Germany has about 100 million people (around 80 million, to be a bit more precise). Since the answer is smaller, you divide by 10 and get 10 million. | Iceland “feels like Alaska” in terms of population density, amount of ice, etc. so they are probably comparable, though Alaska is bigger. You happen to know that Alaska has about 600,000 people, so you guess Iceland, which is smaller geographically, would have 60,000 people. | You happen to know that its capital, Reykjavik, has about 100,000 people. You also know that Iceland has very few “big cities” so the capital is probably a significant part of its population. So you make a guess and multiply it by 2 and get 200,000 people. | You happen to know the answer, because you are into geography. It's around 300,000 people. | . Map highlighting Iceland and Germany . We can already learn quite a few things from this example: . | Much of the skill of estimation is cleverly using what you already know. If you know a lot of things, then it becomes easier to estimate more things. But even if you don't know a lot of things, you can create a solution that works for you personally by using things you know. Much of the enjoyment of doing estimation is finding clever solutions that personally work for yourself. | We see the typical “building block” of estimation: typically, we set up simple algebraic relationships like X=AB, then “solve” for the unknown variable. For example, the second estimate is implicitly saying “the population of Alaska = the population of Iceland * the ratio of their areas” and then “solving” for the Iceland population by dividing the other two. This type of “divide and conquer” makes up for about 90% of the work of estimation. | As an example of how estimation “trains your knowledge,” suppose you did the first estimation and then realized you overestimated. This means you can now conclude (and verify!) “Germany was a bit bigger than I thought” and “Iceland is less dense than Germany.” Now you learned a bit more about the world. If you just looked up the number you would have failed to learn this. | . ",
    "url": "http://localhost:4000/lectures/lec4-estimation/#a-second-warmup",
    "relUrl": "/lectures/lec4-estimation/#a-second-warmup"
  },"60": {
    "doc": "Lecture 4 - Estimation 101",
    "title": "Orders of Magnitude and Fermi",
    "content": "The numbers from our four approaches seem pretty different from each other, but I will now argue they are pretty good! How should we measure the goodness of our estimates? Well, supposing the “right” answer was 300,000 people and you got 400,000 people, then the absolute error (the difference) would be 100,000 people. This feels huge, but if you were estimating the population of the U.S. (300 million people) this amount of error suddenly starts to feel very small. This leads us to instead consider the relative error, the ratio between the estimate and the right answer, instead of the absolute error. In this case, the relative error would be about 1.33. | A relative error of 2 would mean the right answer was X but you got X/2 or 2X. | For bigger absolute errors, we typically use orders of magnitude of the relative error. This means we measure the relative error by powers of 10, so being “one order of magnitude off” from the true answer X means your answer is somewhere between X/10 to 10X, and “two orders of magnitude” would be between X/100 and 100X. | . In this light, all of our estimations were within two orders of magnitude, despite using very non-sophisticated techniques! Estimations are popular among physicists and engineers because it allows them to exercise their mental models of the physical world. They typically do what's called Fermi estimations, where they only care about the order of magnitude. The name “Fermi” refers to the famous event where the physicist Enrico Fermi estimated the strength of an atomic bomb explosion, obtaining an answer of 10 kilotons of TNT while the accepted answer is about 20. Enrico Fermi at a chalkboard . The more you know, the better you will be at getting tighter and tighter relative error bounds. What's “good”, however, is very context dependent: . | In the Fermi example, a relative error of 2 is quite good, and I am guessing being off by an order of magnitude would have been bad for engineering purposes but fine for an estimation. Context matters! | If we are just practicing, then for very big or small numbers (for example, estimating the number of cells in the human body) I think most of us would find an error of within 2 orders of magnitude as “acceptable” and an error within 1 order as “good,” though biologists and/or doctors may want to be harder on themselves! | . ",
    "url": "http://localhost:4000/lectures/lec4-estimation/#orders-of-magnitude-and-fermi",
    "relUrl": "/lectures/lec4-estimation/#orders-of-magnitude-and-fermi"
  },"61": {
    "doc": "Lecture 4 - Estimation 101",
    "title": "More Practice",
    "content": "What is the radius of the Earth? A few things: . | Don't look up anything since it makes this boring. | If you did already know this / looked it up before, you should try to do this some other way - you will still be able to learn something from the training. | If you finish very quickly, you should see if you can do it a different way. Good estimators frequently get the same thing a couple of ways so they can find an even better estimate. | . (practice!) . Cool. How did that go? What I did here is something like this: . | I “know” that the US is about 3000 miles wide. (maybe because I did the previous warmup!) | I know that the US spans 3 time zones, since when I call my mom on the East coast she is 3 hours ahead. | This means each “time zone” is probably about 1000 miles. | I'm guessing there are 24 time zones, so the circumference is probably like 24000 miles. | We know that the circumference is $2\\pi r$, and $\\pi$ is close to 3, so the answer is 24000/6 = 4000 miles. | . I like this approach (there are others!) because it uses things we feel from real life. For example, if you didn't know (1), maybe you could have gotten it with your own experiences. Maybe you did a cross-country drive before and you know it takes about 5 days to drive cross-country doing like 12 hours of driving a day at like 80mp/h. This means you're driving 960 miles a day and the width of the US should be about 5000 miles. This is a bit high but still the right order of magnitude. You probably slept a lot on day 4, or spent too long going through Manhattan in a way unrepresentative of the rest of the trip. Okay, let's try another one. How many McDonalds are there in the US? . (practice!) . This was my approach. Again, this isn't meant to be the “right” approach - I would be very interested to hear what things you did! . | I feel there are probably 4 McDonalds in the Berkeley area, from having lived there a few years. | Sure some cities are bigger and most are smaller, but closing my eyes, I feel there are probably around 1000 “Berkeleys” in California by “overall coverage of McDonalds.” So there are probably 4000 McDonalds in California. | There are 50 states and California is pretty big, so I'll multiply by 10 and get something like 40,000 McDonalds in the US. | I look it up. The answer is 14,000, so I did pretty well (by order of magnitude), but I got it a bit high. So is there something I can improve here? | One place with room for improvement is where I counted California as “about 1000 Berkeleys”. Let's dig into other possible ways to make this estimate: . | By Google (or if we had more time, another estimation!), it looks like Berkeley has 120,000 people and California has 40 million people, so by population there are more like 400 Berkeleys in California. | By geographical area, Berkeley's area seems to be 20 mi^2, and California's area is 163696 mi^2, so you can fit about 8000 Berkeleys in California by size. Lots of California is not as densely populated as Berkeley (e.g. farmland), so maybe there are 8000/10 = 800 “Berkeleys” in California.1 | Since what we want is somewhere in the middle, it still looks like our original estimate of 1000 “Berkeleys” is on the “high end” of what's reasonable, so it makes sense that the number of McDonalds was a bit lower than our original estimate. | . | There are plenty of other places to improve as well! (for example, maybe my intuition of the ratio of California and the US is the weaker one here) | . Google maps highlighting McDonalds around Berkeley . And now I learned something about McDonalds, Berkeley, and California! . ",
    "url": "http://localhost:4000/lectures/lec4-estimation/#more-practice",
    "relUrl": "/lectures/lec4-estimation/#more-practice"
  },"62": {
    "doc": "Lecture 4 - Estimation 101",
    "title": "Summary",
    "content": ". | When in doubt, Google, but estimation is kind of like the weight room for forecasting and reasoning about the world. | It is also very helpful for physicists and surprisingly helpful for things like tech / business interviews, where people use it as a way to test your grasp of the world, so there's some pragmatic reason to get good at them | It turns out that we have a lot of nice intuitions about the world, and estimation allows us to articulate them and get pretty good numbers! | . (Thanks to Frances Ding and Jacob Steinhardt for help preparing this post. Much of this material is based on something I run at SPARC, so thanks to the many people over the years who have contributed to that as well) . | Note you can also do something like estimate that the US is 6,000,000 mi^2 by estimating it as a rectangle with our earlier “result”, and jump straight to “we can fit 300,000 Berkeleys in the US by geographic area,” which you can then downgrade a bit since Berkeley has a higher population density than the average plot of land, to get a more reasonable answer. So the more estimations you do, the better you will be at doing other ones! &#8617; . | . ",
    "url": "http://localhost:4000/lectures/lec4-estimation/#summary",
    "relUrl": "/lectures/lec4-estimation/#summary"
  },"63": {
    "doc": "Lecture 4 - Estimation 101",
    "title": "Lecture 4 - Estimation 101",
    "content": " ",
    "url": "http://localhost:4000/lectures/lec4-estimation/",
    "relUrl": "/lectures/lec4-estimation/"
  },"64": {
    "doc": "Lecture 5 - Zeroth and First Order Forecasting",
    "title": "Lecture 5: Zeroth and First Order Forecasting",
    "content": "Let's say you are trying to predict how long it will take to finish your homework assignment. You think about all the problems and how long each will take. Problem 4 looks a little hard but you're sure if you try real hard you can solve it in 2 hours. Okay, so maybe 7 hours total? Plenty of time to finish if you start the afternoon before it's due! . Of course, the last 3 homework assignments all took between 12 and 16 hours… . You're getting ready to go to class in the morning. Your first class is at 9:10 am. When should you leave? Well, google maps says 8 minutes from your dorm, but if you bike real fast you can do it in 6. So it's probably fine to leave at 9:04… . …you say to yourself, and then get to class at 9:20 (just like the last 3 times). Because of course, you forgot to account for the time it takes to tie your shoes, find your keys, put on your backpack, unlock your bike, lock your bike, and walk to the classroom. These are both instances of the planning fallacy, where humans regularly underestimate the time it takes to finish a task. In the real world, employees and teams that can avoid the planning fallacy have a huge advantage over those that don't. The planning fallacy is an example of a cognitive bias, which we'll talk about in more detail in a later lecture. For now, though, I want to talk about a simple but very effective technique for avoiding the planning fallacy, and more generally for making accurate predictions, called reference class forecasting. ",
    "url": "http://localhost:4000/lectures/lec5-zeroth-first/#lecture-5-zeroth-and-first-order-forecasting",
    "relUrl": "/lectures/lec5-zeroth-first/#lecture-5-zeroth-and-first-order-forecasting"
  },"65": {
    "doc": "Lecture 5 - Zeroth and First Order Forecasting",
    "title": "Reference Class Forecasting (Zeroth-order Approximation)",
    "content": "The basic idea behind reference class forecasting is simple: rather than thinking in detail how about how long a task will take (or about any other prediction), just think of the last 3-5 instances where something similar happened, and give the average answer. So for homework, a good predictor of how long it takes to complete is the average of other problem sets for that class. For commute time, take the average commute time over the past week. A more mathematical way to think of reference class forecasting is as a zeroth-order approximation: we are assuming that today will look like yesterday, i.e. that the world is roughly constant. This works for more than just avoiding the planning fallacy. For instance, it's also useful when making a budget. In the policy world, carbon emissions next year is probably well-predicted by carbon emissions over the last few years. Brainstorming exercise. What are other areas where a zeroth-order approximation might work well? . ",
    "url": "http://localhost:4000/lectures/lec5-zeroth-first/#reference-class-forecasting-zeroth-order-approximation",
    "relUrl": "/lectures/lec5-zeroth-first/#reference-class-forecasting-zeroth-order-approximation"
  },"66": {
    "doc": "Lecture 5 - Zeroth and First Order Forecasting",
    "title": "First-order Approximation",
    "content": "There's some cases where a zeroth-order approximation isn't very helpful. In February 2020, if you were thinking about the coronavirus, there were several zeroth-order approximations you could have made: . | Look at the world generally, and assume that it will look at the end of March like it did in the middle of February. | Or similarly, look at the number of available ICU beds and assume it will stay roughly the same. | Or assume the number of Covid cases will stay roughly the same. | . I think if you asked most people, they would have disagreed with assumption 3. But most people were implicitly applying a zeroth-order approximation to 1. when thinking about the future. A better strategy would have been to apply a first-order approximation, to the number of Covid cases, i.e. to trace a line through the recent data points and to use this line to predict future data points. You could then have used this approximation instead of assumptions 1. and 2. to predict the overall state of the world and the number of available ICU beds. For example, here's what the data would have looked like in the United Kingdom at the end of February 2020: . Here you can see the number of confirmed Covid cases per million in the UK, between early February 2020 and late February 2020. Feel free to play around with the dates to see how well and for how long tracing a line through the data would have worked! . You can also switch between a linear and a logarithmic scale, i.e. between plotting the number of confirmed cases per million, and its logarithm. A first-order approximation to the logarithm of a quantity predicts that that quantity grows exponentially. In the case of confirmed cases, this approximation is quite inaccurate between late January 2020 and late February 2020, but does quite well between the end of February 2020 and the middle of March 2020. Note that the choice of what to first-order approximate matters a lot here. If you had applied a first-order approximation to 1. or 2., you wouldn't have thought much would change. Discussion question. How can we decide which variables are good ones to first-order approximate? . Brainstorming question. What are some other areas where first-order approximation can be powerful? Would you use linear or log space? . ",
    "url": "http://localhost:4000/lectures/lec5-zeroth-first/#first-order-approximation",
    "relUrl": "/lectures/lec5-zeroth-first/#first-order-approximation"
  },"67": {
    "doc": "Lecture 5 - Zeroth and First Order Forecasting",
    "title": "Breakdowns of First-order Approximation",
    "content": "In many cases, there's some clear limit to growth, which means the first-order approximation has to stop eventually. For instance, Tesla's revenue has grown around 50%/year from 2015 to 2020. If it continues at this rate, then it would account for &gt;50% of the U.S. economy by 2035. This seems unlikely, so the growth will probably slow down sometime before then. As a more extreme example, the number of compute-hours used in the largest AI experiments grew around 10x/year between 2012 and 2018. This probably can't continue for more than 6-7 years before matching the world's total current hardware budget. And as an example that already happened, in early 2020 the number of COVID-19 cases was doubling perhaps every 4.5 days. Starting from a few hundred cases, a first-order approximation of its logarithm would have predicted that everyone in the world would be infected within 4 months. While many people have been infected (I'd guess around 10%), it's not everyone, and it took much longer than 4 months. All of these are examples of saturation effects: fast-growing trends tend to eventually run into countervailing forces that limit the rate of growth. It's not always easy to predict exactly when these will kick in, but looking at hard limits like those above can help provide some bound. On the other hand, I think most people intuitively underestimate how long trends last. (If you asked me to predict how long the Tesla and AI trends will last, I'd say 5 years for Tesla and 4 years for AI.) . One common way to model saturation effects is with a sigmoid curve, which starts out exponential and then flattens. This works best when there is an obvious limit that the curve should approach (for instance, accuracies usually approach 100% or a bit less). However, I think that in many cases, growth tends to continue at a slower pace instead, so a sigmoid is less appropriate. ",
    "url": "http://localhost:4000/lectures/lec5-zeroth-first/#breakdowns-of-first-order-approximation",
    "relUrl": "/lectures/lec5-zeroth-first/#breakdowns-of-first-order-approximation"
  },"68": {
    "doc": "Lecture 5 - Zeroth and First Order Forecasting",
    "title": "Breakdowns of Zeroth-order Approximation",
    "content": "Here's another example question: How many deportations were there under the Trump administration in 2018? For comparison, here are numbers under Obama and Bush: . | Year | Deportations | . | 2016 | 332,227 | . | 2015 | 325,668 | . | 2014 | 405,239 | . | 2013 | 432,281 | . | 2012 | 415,636 | . | 2011 | 390,442 | . | 2010 | 382,461 | . | 2009 | 379,739 | . | 2008 | 359,795 | . | 2007 | 319,382 | . | 2006 | 280,974 | . | 2005 | 246,431 | . | 2004 | 240,665 | . | 2003 | 211,098 | . | 2002 | 165,168 | . | 2001 | 189,026 | . Actually, this was a trick question: zeroth-order approximation works great here, and the answer was 337,287. But it would have worked less well for another immigration-related statistic: border apprehensions. (Source: Pew Research) . If I were really trying to figure out whether a government statistic like this could be reliably zeroth-order approximated, I'd try to figure out how much direct power the executive (or the executive's appointees) had over that statistic, and how much historical volatility that statistic had. I don't have a good answer to the former, but looking at the latter suggests that border apprehensions can change pretty rapidly and have done so before: . Brainstorming exercise. What are other places where zeroth-order (and even first-order) might not work well? How could we tell? . ",
    "url": "http://localhost:4000/lectures/lec5-zeroth-first/#breakdowns-of-zeroth-order-approximation",
    "relUrl": "/lectures/lec5-zeroth-first/#breakdowns-of-zeroth-order-approximation"
  },"69": {
    "doc": "Lecture 5 - Zeroth and First Order Forecasting",
    "title": "Synthesizing Zeroth- and First-order",
    "content": "Some of the examples above show that a first-order prediction in one area often contradicts a zeroth-order prediction in another. For instance: . | The first-order approximation for the number of COVID-19 cases contradicted the zeroth-order approximation for the number of lockdowns. | The first-order approximation for Tesla's growth contradicts the zeroth-order approximation for the US economy. | . Note that in the first case the first-order approximation was correct, while in the second I'd guess the zeroth-order approximation is more correct. So in general, how do we resolve conflicting forecasts like this? . Brainstorming exercise. When a zeroth-order and first-order prediction conflict, what are some heuristics we could use to decide which one to follow? . ",
    "url": "http://localhost:4000/lectures/lec5-zeroth-first/#synthesizing-zeroth--and-first-order",
    "relUrl": "/lectures/lec5-zeroth-first/#synthesizing-zeroth--and-first-order"
  },"70": {
    "doc": "Lecture 5 - Zeroth and First Order Forecasting",
    "title": "Lecture 5 - Zeroth and First Order Forecasting",
    "content": "| ",
    "url": "http://localhost:4000/lectures/lec5-zeroth-first/",
    "relUrl": "/lectures/lec5-zeroth-first/"
  },"71": {
    "doc": "Lecture 6 - Base Rates and Reference Classes",
    "title": "Lecture 6: Base Rates and Reference Classes",
    "content": "Let's start by considering the following question: . What is the probability that Joe Biden is President of the United States on Nov. 1st, 2024? . [Note: This was written on Nov. 3rd, 2021.] . To answer this question, one strategy I would use is to look at base rates: the rate of occurrence of similar events. For instance: . | What fraction of presidential terms are fully completed (last all 4 years)? The answer to this is 49 out of the 58 total terms, or around 84%. | On the other hand, we know that Biden has already made it through 288 days of his term. If we remove the 5 presidents who left office before that, there are 49 out of 53 or around 92%. | But alternately, Joe Biden is pretty old (78 to be exact). If we look up death rate per year in actuarial tables, it's around 5.1% per year, so this leaves him with a ~15% chance of death or a 85% chance of surviving his term. | . These are all examples of using base rates. Base rates can be powerful as they allow us to draw analogies with related cases even when we don't have directly relevant data or a trend line to extrapolate. In that sense they are like zeroth-order forecasting, but can work even when you don't have a clear time series or other trend to base a forecast on. ",
    "url": "http://localhost:4000/lectures/lec6-base-rates/#lecture-6-base-rates-and-reference-classes",
    "relUrl": "/lectures/lec6-base-rates/#lecture-6-base-rates-and-reference-classes"
  },"72": {
    "doc": "Lecture 6 - Base Rates and Reference Classes",
    "title": "Decomposing the Problem",
    "content": "We can take base rates one step further. If Biden doesn't complete his term, the main reasons I can think of are: . | Death by natural causes | Death by assassination | Impeachment / resignation | The presidency no longer exists (due to a coup, invasion, etc.) | . So, we could estimate all of these using base rates, then add them up. The last two are easiest: only one president has left office due to resignation (Nixon), so 1 out of 58 on impeachment / resignation. I'd put the presidency no longer existing at &lt;1%, so together these add up to maybe 2%. [At the time of writing, PredictIt gave Biden a 22% chance of resigning before the end of his term. I feel confused about this.] . Death by assassination: 4 out of 58 presidents, or around 7%. But only one of these was more than 288 days into the term, which would instead give 1.7%. I would subjectively put the probability a bit between these, at 3.5%. Death by natural causes: we previously gave this a 15% chance. But that's neglecting that life expectancy increases with income, and Biden is pretty rich. Eyeballing the mortality curves here, I'm going to guess that this decreases his probability of death to around 60% of its baseline value. So we end up with 9% instead of 15%. Adding these together gives 2 + 3.5 + 9 = 14.5%. So an 85.5% chance of completing his term. What did we gain from applying this decomposition? The main thing is that it allows us to incorporate age when predicting death from natural causes, which feels correct to me. On the other hand, it left us with a very small sample size for assassinations, and in general left us to make a lot of arbitrary choices that might let personal biases creep in. That being said, the number is in the same ballpark but a bit lower than the 92% answer from the simplest method, which feels right given Biden's age. ",
    "url": "http://localhost:4000/lectures/lec6-base-rates/#decomposing-the-problem",
    "relUrl": "/lectures/lec6-base-rates/#decomposing-the-problem"
  },"73": {
    "doc": "Lecture 6 - Base Rates and Reference Classes",
    "title": "Other Examples",
    "content": "There are many cases where base rates are a useful tool. For instance, maybe I want to understand the probability that I get Covid in the next month (perhaps as a function of what activities I do). Brainstorming exercise. What base rates would you use for the above question? What factors are most important to take into account? . Here are some other questions where base rates provide valuable information: . | What job will I have after I graduate Berkeley? | How much Series A funding will this startup get? | Will someone break Usain Bolt's 100-meter dash 9.58s world record by the end of 2024? | Will China send a daily record number of military planes into Taiwan's air defense identification zone next month? (from CSET Foretell) | . Brainstorming exercise. What are other areas where base rates are helpful? . ",
    "url": "http://localhost:4000/lectures/lec6-base-rates/#other-examples",
    "relUrl": "/lectures/lec6-base-rates/#other-examples"
  },"74": {
    "doc": "Lecture 6 - Base Rates and Reference Classes",
    "title": "Dangers of Base Rates",
    "content": "As I hinted above, the flexibility of base rate forecasting also carries risk. If we make too many arbitrary choices when defining a base rate, we can succumb to our own cognitive biases. For instance, consider the following article that gave Trump a 3% chance of winning the 2016 election. Its reasoning invokes base rates, defining a reference class of “Candidates that are good with the media and give them something to write about but, let's be real, could never be president”. They said Trump was in this reference class and no such candidate had ever won, so their base rate was 0%. (They then adjusted it up to 3% based on Trump's strong polling performance.) If you find yourself doing something like this, watch out. Pro tip: Don't do this. The best ways to avoid failures like the Trump prediction are to look for the simplest reference classes you can find (only adjusting for obviously important and objective factors like age), or to average over lots of ways of constructing your reference class so that no single set of choices dominates the forecast. ",
    "url": "http://localhost:4000/lectures/lec6-base-rates/#dangers-of-base-rates",
    "relUrl": "/lectures/lec6-base-rates/#dangers-of-base-rates"
  },"75": {
    "doc": "Lecture 6 - Base Rates and Reference Classes",
    "title": "Base Rates for Events That Haven't Happened",
    "content": "What about base rates for events that have never happened? For instance, suppose that no U.S. president had ever resigned: should we really give a 0% probability of that happening to Biden? Probably not. A rough rule of thumb is that if an event has had \\(n\\) opportunities to occur but has never happened, we assign probability \\(\\frac{1}{n+2}\\) to it happening the next time. So for instance, if someone is late to their first two meetings with me, I assign 25% probability to them being on time the next time. To use this rule of thumb, we need to decide what \\(n\\) is. In the case of presidents resigning, \\(n = 45\\) seems pretty reasonable, but other situations can be more complicated. For instance, suppose we want to estimate the probability of military conflict between France and the United States in the next year. How far back should \\(n\\) go: e.g., should the Quasi-War influence our credence? . Here are some other examples where we care about events that haven't happened yet: . | What is the probability of fully self-driving cars by 2030? | What is the probability that we develop a cure for diabetes by 2025? | What is the probability the FDA approves Paxlovid by Jan. 1st, 2022? | What is the probability of California seceding from the U.S. by 2025? | . Exercise. How would you choose \\(n\\) in the above cases? How reasonable does the \\(n+2\\) rule seem in each case? Are there any cases where an alternative prediction method seems better? . Generalization and alternatives. The \\(n+2\\) rule is a special case of Laplace's rule of succession, which addresses a more general problem: if I repeat an experiment \\(n\\) times, and am successful in \\(s\\) of the \\(n\\) trials, what is the probability that I will be successful in trial \\(n+1\\)? Laplace's rule provides the estimate \\(\\frac{s+1}{n+2}\\), which in the special case \\(s = 0\\) yields the \\(\\frac{1}{n+2}\\) recommendation above. Laplace's rule is formally derived by assuming that the events are i.i.d. and that their true probability \\(p\\) has a uniform prior, and then applying Bayes' rule. The uniform prior can have strange implications: it implies that when \\(n = 0\\) (no observations so far), we should assign 50% probability to the event happening. For presidents resigning, this means assigning 50% probability to the first president resigning, which seems too high. If you asked me to imagine the probability that George Washington would resign, I would've guessed something like \\(\\pi = 0.25\\). A simple generalization of the \\(n+2\\) rule to this case is to predict \\(\\frac{1}{n + (1/\\pi)}\\). So for \\(n = 45\\) presidents I would give a \\(\\frac{1}{49}\\) probability of resigning, which is a bit smaller than the prediction from the \\(n+2\\) rule. The above “\\(n + (1/\\pi)\\)” rule can also be justified mathematically, using a different prior than the uniform distribution. We can often determine a good prior by appealing to some higher-level reference class. For a good example of this, I'd recommend looking at Tom Davidson's report on semi-informative priors for AI development. Brainstorming exercise. Suppose that instead of picking \\(\\pi\\) intuitively in the George Washington example, we wanted to set \\(\\pi\\) using a base rate. What reference classes could we use? . ",
    "url": "http://localhost:4000/lectures/lec6-base-rates/#base-rates-for-events-that-havent-happened",
    "relUrl": "/lectures/lec6-base-rates/#base-rates-for-events-that-havent-happened"
  },"76": {
    "doc": "Lecture 6 - Base Rates and Reference Classes",
    "title": "Lecture 6 - Base Rates and Reference Classes",
    "content": "| ",
    "url": "http://localhost:4000/lectures/lec6-base-rates/",
    "relUrl": "/lectures/lec6-base-rates/"
  },"77": {
    "doc": "Lecture 7 - The \"Other\" Option",
    "title": "Lecture 7: The “Other” Option",
    "content": "For open-ended questions, it's easy to underestimate the number of plausible outcomes. For instance, while practicing for the forecasting class, the course staff were asked to predict the following question: . Which NBA player will have the highest average points per game (PPG) between October 20th and October 27th? . To answer this question, I thought about star players who were top scorers, and also looked at who had high PPG in the previous season. The names I came up with were Giannis Antetokounmpo, Steph Curry, Luka Doncic, Kevin Durant, and LeBron James, so I made the following forecast: . | Giannis 19% | Curry 17% | Doncic 16% | Durant 13% | LeBron 12% | Other 23% | . In fact, the top scorer was Ja Morant, and the second highest scorer also wasn't on my list. In retrospect, 23% on “other” was a pretty bad prediction, and I should have put more like 60-70% on “other”. This is a general challenge with forecasting when the set of options is large. Even if each individual choice in the “other” category isn't that likely, there are a lot of choices in that category, and they add up to a large number. For instance, there are 30 teams in the NBA, so even counting just the best player on each team, my top-5 list was missing 83% of the options. Even if the other 25 starters were each only half as likely as LeBron to top the PPG, they would account for 66% of the probability mass. Our tendency to underestimate “other” is worsened by the narrative fallacy, which is our cognitive tendency to frame events in some logical coherent order, and the disjunction fallacy, where the whole is often estimated to have lower probability than the parts. It's easy to imagine Curry scoring lots of points, but harder to imagine Ja Morant (although he is quite good), and even harder to imagine “some random player” scoring a lot. Misha: You bring up misc cognitive biases. My default explanation would be availability bias. Per wikipedia: “Availability bias, is a mental shortcut that relies on immediate examples that come to a given person's mind when evaluating a specific topic, concept, method or decision.” . On the other hand, there are times when “other” really does have a low probability. For instance, in a given week there's really only 1 or 2 movies that have a real chance of topping the box office returns. Since deciding the right probability for “other” is surprisingly difficult, it's worth practicing as a distinct skill. In this post, I'll discuss two ways of handling it: the MECE principle, and reasoning about variance. I'll also end with some quotes from Misha on good cognitive strategies for handling “other” options. ",
    "url": "http://localhost:4000/lectures/lec7-other-option/#lecture-7-the-other-option",
    "relUrl": "/lectures/lec7-other-option/#lecture-7-the-other-option"
  },"78": {
    "doc": "Lecture 7 - The \"Other\" Option",
    "title": "The MECE Principle",
    "content": "The MECE principle, which stands for “mutually exclusive and collectively exhaustive”, is a special case of decomposing the problem. It's pretty much what it says: write down a set of options that exhausts the set of possible outcomes, and come up with a probability for each one. At face value, this would mean not having an “other” option at all, but this is usually impractical—we're not going to assign a probability for all 450 players in the NBA. But even so, MECE can be useful. For instance, realizing that there were 30 teams (and hence 30 “best players”) highlighted that the top 5 options didn't cover much of the space. If I were to apply MECE to the NBA prediction, I'd break it down as something like: . | 5 “super-scorers” | 25 other “best players” | 30 “second-best players” | ~120 other players who get “significant playing time” | ~270 “bench” players who get limited playing time | . To make some numbers up, maybe I think each super-scorer is on average 3x as likely to top the PPG as the other 25 best players, and on each team the best player is on average 4x as likely as the next best player to top the PPG. To turn this into a probability, we'll add up all the possibilities, using the fact that probabilities sum to 1 and working backwards. Concretely: let $p$ be the average probability that a super-scorer has the highest average PPG. Then among the 30 players in the first 2 categories, we have a total probability mass of . $5 \\times p \\textrm{ (super-scorers) } + 25 \\times (p/3) \\textrm{ (other best players)} = 13.33p$ . And including the next tier of second-best players should increase the total mass by another 25% (since they're 1/4 as likely), to get to $16.66p$. If this were all the probability mass, then $p = 1/16.66 = 0.06$, so the super-scorers have $5p = 30\\%$ of the probability and other players have $70\\%$ of the probability. In actuality, the other 30+120+270 players have some probability mass. Maybe the second-best players are 10% as likely, the third-best players are 4% as likely, and so on. This collectively doesn't add much–maybe it increases the calculation above to around $19p$ instead of $16.66p$. This would mean that “other” had 74% probability instead of 70%, so not a huge difference. (This all glosses over the fact that the different players' points-per-game are not independent of each other, and thinking about this would probably change the answer a bit, but hopefully this illustrates the idea.) . MECE for box office scores. As another example, let's apply MECE to predicting which movie tops the box office this weekend (the weekend of Nov. 13th, 2021). If I go to reddit.com/r/boxoffice, I see that there are around 10 choices: Eternals, Clifford, Dune, Belfast, No Time to Die, Venom, Ron's Gone Wrong, The French Dispatch, Spencer, and Antlers. Most people in the predictions thread are predicting Eternals at around \\$25M, Clifford around \\$12M, Dune at \\$5M, No Time To Die at \\$4M, and the rest below that. It's hard for me to imagine these being off by a factor of more than 5 (if I were being careful I'd check that historically that basically never happens), so it would be safe to assign probabilities to Eternals, Clifford, and Dune, and place everything else at something pretty small in total (maybe even as small as 1%, or a bit higher to account for the probability that I misread the list). MECE is nice because it correctly demonstrates that the NBA prediction should place lots of probability on “other”, and the box office prediction not so much. Misha: On MECE — I think it's an excellent approach whenever it works. For it to work, you need to be able to enumerate space of possibilities or approximate it somehow. I think your examples are good and helpful. MECE + Programming . The other way to apply MECE to this example would be to come up with a simple heuristic to predict the probability, and then write a script to compute it for all the players. Even if the heuristic ignores a lot of specific relevant details, it will probably be okay on average and so give a good estimate of the relative magnitude of “other” vs. the top 5 or 10 options. For the NBA example, I could grab the list of each player's scores from the previous season, look at all the weeks, and see how often each player comes up on top. This will miss differences across seasons (such as injuries or player improvement) and miss specifics of the upcoming week and probably several other factors, but this probably affects the “other” and “top scorer” categories roughly similarly and will give a reasonable estimate of the ratio. I in fact ran this script for the first 18 weeks of the 2020-2021 season, and here are the results: . I listed each player that led scoring for at least one week, and also included their season total points/game (PPG) and points (Pts), as well as how they ranked among all players. Out of 18 weeks, the top 2 scorers (Curry and Beal) led 5 and 4 times each. But the 3rd scorer (Lillard) led only once, and none of the other weekly leaders were in the top 6. To cover all 18 weeks, you'd have to go down into the 30s. This implies that historically, if you had listed the top 6 players, you would have missed 8/18 = 44% of weeks. But this top 6 list has the benefit of hindsight at the end of the season, whereas in our case we were predicting a new season and should have more uncertainty. So this is consistent with the 60%-70% estimate for “other”. ",
    "url": "http://localhost:4000/lectures/lec7-other-option/#the-mece-principle",
    "relUrl": "/lectures/lec7-other-option/#the-mece-principle"
  },"79": {
    "doc": "Lecture 7 - The \"Other\" Option",
    "title": "Noise and Power Laws",
    "content": "Another approach would be to think about how noisy a player's point total is for a given week, and how that compares to the difference in points across players. For the latter, here were the top 3 scorers for the first 3 weeks of January 2021: . | Date | Rank | Player | Pts | . | 2021-01-04 | 1 | Curry,Stephen | 149 | . | 2021-01-04 | 2 | Brown,Jaylen | 137 | . | 2021-01-04 | 3 | Tatum,Jayson | 135 | . | 2021-01-11 | 1 | Beal,Bradley | 135 | . | 2021-01-11 | 2 | LaVine,Zach | 133 | . | 2021-01-11 | 3 | Hayward,Gordon | 117 | . | 2021-01-18 | 1 | Lillard,Damian | 133 | . | 2021-01-18 | 2 | Durant,Kevin | 132 | . | 2021-01-18 | 3 | Dončić,Luka | 113 | . The winner was decided by 12, 2, and 1 points, respectively. On the other hand, here is the variation in weekly points for the top 6 scorers in the NBA: . The standard deviation is huge, around 30 points. This immediately tells us that there are a lot of people who “could” win in a given week. Since there are 3-4 games in a week, anyone whose average points/game is within 7.5-10 points of the leader is within 1 standard deviation. This comes out to ~17-25 players. If we compare to our earlier result, 16/18 of the weekly leaders were in the top 17 PPG, and 17/18 were in the top 25, so this is the right ballpark for the set of “plausible” options. Misha: I am not knowledgeable about the NBA. One thing which strikes me immediately: the time interval is short, the variance will be huge; this is on top of basketball being a fairly high variance game in general. And to connect these intuitions to common probability distributions: . | Each player's points in a given week is probably Gaussian-ish (very unlikely to exceed 200, so more like heights than Twitter followers). | But the points per game as distributed across players is more like a power law: a small number of players score most of the points, but there's also a long tail. | . The power law intuition tells me that once we start going into the tail, we'll have to go pretty far before we run out of options. The difference between the 2nd and 3rd ranked scorers (Beal and Lillard: 31.3 vs. 28.8) is the same as the difference between the 10th and 20th ranks (Tatum and Ingram: 26.4 vs 23.8) . ",
    "url": "http://localhost:4000/lectures/lec7-other-option/#noise-and-power-laws",
    "relUrl": "/lectures/lec7-other-option/#noise-and-power-laws"
  },"80": {
    "doc": "Lecture 7 - The \"Other\" Option",
    "title": "Cognitive Tricks for Remembering “Other”",
    "content": "While math can build useful intuition, what's probably more important is good mental heuristics for remembering “other” options. Here is Misha's commentary on this: . It's quite often helpful to ask: “huh, could I forget about another option which will sound plausible” — I usually do it for open-ended questions, and it helps me moderate my guesses. A good example is any trivia, an open-ended question. After thinking more about my calibration, I started annoying people by saying that I think the answer is X with a probability of like 20%. They expect certainty and, unfortunately, don't update on both of us betting on wrong answers. Other options occur everywhere. Finally, Misha points out that it's often useful to think about other options even for questions that appear to have a small choice set (e.g. yes/no questions): . I would say that the “other” option appears more often than people think, and your post implies. Fairly often, I use the above heuristic while doing geopolitical forecasts. For geopolitical forecasts, it's sometimes helpful to try to get a better world model and outline plausible scenarios. But this is faulty as one might oversubscribe to a particular scenario. One of the most satisfying forecasts I've ever made was about whether Saudi Arabia would cancel Hajj because of coronavirus. The question's framing promoted black and white thinking, and just asking whether there could be other solutions led us to come up with a few which were plausible (and which, imo, would better satisfy stakeholders). So asking “could I not think about something which will sound plausible” is very helpful! . ",
    "url": "http://localhost:4000/lectures/lec7-other-option/#cognitive-tricks-for-remembering-other",
    "relUrl": "/lectures/lec7-other-option/#cognitive-tricks-for-remembering-other"
  },"81": {
    "doc": "Lecture 7 - The \"Other\" Option",
    "title": "Lecture 7 - The \"Other\" Option",
    "content": " ",
    "url": "http://localhost:4000/lectures/lec7-other-option/",
    "relUrl": "/lectures/lec7-other-option/"
  },"82": {
    "doc": "Lecture 8 - The Inner Game of Forecasting",
    "title": "Lecture 8: The Inner Game of Forecasting",
    "content": "Yan Zhang . Forecasting is much more like a sport than a collection of knowledge. One benefit of sports and similar skills, like games, is that they provide ways to get feedback quickly and improve. In this class, we will focus on one main game, “predict X by time Y”, and we will play this game many times. Therefore, there is potential for significant improvement on that skill over a semester. In contrast, most math classes have to cover a certain amount of material, so you only get a few hours of practice on a given topic. Thus, our ambitious (really!) goal is to teach forecasting in such a way that you get better at the game of forecasting instead of just providing knowledge and references about forecasting. In this lecture, we will try to provide some “good” mindsets to actually get better at forecasting as an accompaniment to specific techniques in other lectures. There are two main points in this lecture. | Deliberate practice is key to actually improve at forecasting, and by practicing efficiently, you can improve much faster than with poor practice. | When practicing, your feelings and intuitions are very important. | . ",
    "url": "http://localhost:4000/lectures/lec8-inner-game/#lecture-8-the-inner-game-of-forecasting",
    "relUrl": "/lectures/lec8-inner-game/#lecture-8-the-inner-game-of-forecasting"
  },"83": {
    "doc": "Lecture 8 - The Inner Game of Forecasting",
    "title": "Good Practice",
    "content": "The first thing that can improve any practice is feedback. Whenever we practice any skill, by default people tend to just put in the hours and hope they get better at it. However, we can learn more efficiently by adjusting based on results - since forecasting is often grounded in reality! For starters, if you just do more of what got “good” results and less of what got “bad” results, you will learn faster (a caveat is that: what's “good” and what's “bad” is context-dependent and might be hard to tell; for example, if the “right” answer was in your 80% confidence interval, than that's “good” unless it happens 99% of the time). Of course, this would require you to look at your results after the fact with a critical lens and not just blame everything on bad luck - that's a sure way of spending many hours without ever improving. Now, to up this a level, instead of getting feedback only from results, you may also want to look at your reasoning. This is especially important in games with a high amount of randomness (such as poker, but also forecasting!), where often you'll get “good” results from doing “bad” actions and vice-versa. As an example, suppose you guessed that presidential candidate Triden will win the next election with high probability because Triden will “definitely” win all of Michigan, Virginia, and Georgia, but Triden actually loses all 3 and wins anyway thanks to swinging California. In this case, you got a good result from faulty reasoning (of course, one can also argue that this really actually was an outlier that you had no ability to predict, but it is easy to make self-serving excuses). This would be a good time to consider your reasoning “bad” and see what you can do to improve it. Getting feedback on reasoning is harder than getting feedback on results, mostly because you are the same brain that made the faulty reasoning the first time around! Two specific ways to improve this are: . | Get external feedback such as talking your reasoning through with friends or looking at other people's points of view: were there key considerations you missed in your model? Were there considerations you included but overrated/underrated? . | Build up a general decomposition of forecasting into sub-skills (such as calibration, estimation, etc.) and look at how they did individually to get feedback on them. For example: . | You may have decomposed the original forecasting question into intermediate forecasting or estimation problems (for example, recall the question about whether Biden would be in office in November 2024). Do you think your decomposition was misleading, or do you think it was basically right, but that your intermediate probabilities and estimates were mistaken? | Were your point estimates good but your intervals too narrow? | Were your base rates good? Did you rely on them too much or too little? | If your forecasts were informed by your personal experience, did you rely on that too much or too little? | . | . As a final point, I really do want to reiterate that it is very easy to become overconfident in your skills due to randomly getting good results; this is a big part of what makes learning poker difficult in a way not applicable to many other games. For starters, I predict that at least 4 out of the top 5 students on the leaderboard right now will no longer be in the top 10 by the last day of the class, so don't get too complacent! (do try to make me eat my words) . ",
    "url": "http://localhost:4000/lectures/lec8-inner-game/#good-practice",
    "relUrl": "/lectures/lec8-inner-game/#good-practice"
  },"84": {
    "doc": "Lecture 8 - The Inner Game of Forecasting",
    "title": "Thinking about Feelings",
    "content": "Now, we get to the second point: “feelings are important”. What do we mean by that? The Inner Game of Tennis by Timothy Gallway is a book that's ostensibly about tennis instruction but applies to many other skills, including forecasting. In it, the author spends a lot of time on introspection, visualization, and feelings. For example, if you're learning tennis, a coach might tell you to hit a forehand by snapping your wrists in a certain way, via a set of verbal instructions. If you just memorize these verbal instructions and try to explicitly follow them, your forehand probably won't improve much. First, explicitly remembering the verbal instruction right before you hit the ball doesn't straightforwardly lead to making the right move. Indeed, it's hard to consciously decide which muscles you should move, and how and when you should move them, especially in such a short period of time. Second, focusing on the verbal instruction may interfere with other important aspects of your stroke. Instead, the goal of the verbal instruction is for you to hit the next few forehands while paying attention to how your wrists can snap in different ways, to progressively build an internal sense of how it feels to move your wrists in the right way. The learning doesn't happen when the coach utters the verbal instructions: it happens as you practice and acquire this intuition for what it feels like to hit a good forehand. Similarly, in this class, we will give you some verbal and written instructions about specific techniques, with names like Base Rates or Zeroth-Order Forecasting. However, if you just treat them as mathematical recipes to follow, you might find them hard to apply directly in practice (and when you do, you may miss bigger elephants in the room in the context of a specific forecast). What's important is to actually get practice doing forecasting, discussing and/ reviewing forecasts, and to get a good feel for what seem to be the important and unimportant parts of a question. Consider the idea/technique of zeroth-order / first-order approximations. The reason we introduce this technique is not to reduce forecasting to fitting a line and forgetting about the original question, as one might in an introductory statistical exercise about linear regression. Instead, the point is that zeroth or first-order approximations are (usually) a good idea to try, after which they become one among many possible “voices” in your final forecast. After you do this a lot, you may learn when first-order approximations are important and when they are not. As an elementary but useful example, suppose you want to predict whether your favorite football team will win its next game. A first-order approximation of the team's performance based on its performance in the last four games this season could definitely be useful, but you may learn that checking the injury list for the status of the team's best players is a “voice” that is often more important than your statistical extrapolation. So just to practice what we are talking about for a bit, let's consider the following question: . What is the price of a 20-year lease of this billboard on the I-80 in downtown SF? . Okay, now that you have had a bit of time to think, can I have some volunteers to explain their reasoning? (5 minutes) . Thanks for the feedback! So the answer to the question is $11,500,000. Now, instead of worrying about whether you got it “right” or not, what I want you to pay attention to, in the spirit of the lecture, are the factors you used and the factors that other people, whether me or your classmates, have come up with. Now I want you to contemplate those factors and get a good feel for which ones seem more important, which ones seem less important, which ones you want to pay more attention to later since you had never thought of them, etc. This is the valuable thing to take away from this exercise. You'll see these ideas explicitly baked into many of our exercises for the rest of this class - and even if not explicit, we think you'll benefit from applying them instead of just thinking of this class as “learning concepts”. So to get the most from these classes, we think you should: . | Practice the explicit “trick” a few times to gain familiarity, such as through the homework. | When you do forecasts, try to apply the new tricks (and the old ones!) that apply, creating many “moving pieces” that must then be filtered/synthesized to create an explicit forecast. | Look at if and when these different moving pieces make your predictions better, and build an intuition for when to use each thing more or less. | Take more initiative socially; talking to other people about forecasting is very valuable; even two forecasters of similar abilities can have very different ideas, strengths, and weaknesses. | . Perhaps most counterintuitively, since this is a statistics class, pay attention to your feelings and intuition when practicing forecasting. This allows you to build a “library” of what it feels like when you are making a good forecast vs. bad forecast, when you're under vs. overconfident, etc. Your internal neural net is much more powerful than you think, but you need to give it a lot of data and tell it to pay attention to specific parts of the data. ",
    "url": "http://localhost:4000/lectures/lec8-inner-game/#thinking-about-feelings",
    "relUrl": "/lectures/lec8-inner-game/#thinking-about-feelings"
  },"85": {
    "doc": "Lecture 8 - The Inner Game of Forecasting",
    "title": "Summary",
    "content": "I have quite a bit of personal data on two types of people that other people generically call “mathematicians”. The first type is the “mathematical theory builders” (e.g. professors and industry researchers who develop theories) who almost always have a Ph.D. and are good at having very deep knowledge of particular field(s) of mathematics. The other type I call “mathematical problem solvers” (e.g. some professors and researchers, but also engineers and consultants) who are very good at solving a broad range of problems with elementary methods, especially in contests, puzzles, and organic industry problems. While these people do a lot of similar things (read papers, solve problems, create mathematical ideas), at least for me, I feel their proficiencies can be very different. “Theory builders” seem very good at absorbing specialized fields of knowledge; they are good at making connections between different theories and theorems and summarizing very abstract and complex packages of thought. Their knowledge is often broad but is first and foremost deep. “Problem solvers”, on the other hand, are very good at generating many hypotheses, killing off unpromising ideas, and reframing problems in different languages. Their knowledge is often deep but is first and foremost broad. For me, forecasting feels like a skill much closer to problem solvers than theory builders. Indeed, when I meet strong forecasters, I have been struck by their similarity to problem solvers; strong forecasters generate many models and hypotheses, are quick to kill off unpromising ideas, and often rely on broad instead of deep knowledge. Therefore, I think the “inner game” mentioned in this post makes for a very good fit for a forecasting class. Good luck, and I hope we (hey, this applies to myself and the other staff, as well!) actually get better at forecasting instead of learning about forecasting! . (Thanks to Jacob Steinhardt for providing a lot of initial structure and ideas, Alex Lawson / Misha Yagudin for valuable conversation from the perspective of skilled forecasters, and Jean-Stanislas Denain for helping with writing / editing. Many of the points here come from The Inner Game of Tennis.) . ",
    "url": "http://localhost:4000/lectures/lec8-inner-game/#summary",
    "relUrl": "/lectures/lec8-inner-game/#summary"
  },"86": {
    "doc": "Lecture 8 - The Inner Game of Forecasting",
    "title": "Lecture 8 - The Inner Game of Forecasting",
    "content": " ",
    "url": "http://localhost:4000/lectures/lec8-inner-game/",
    "relUrl": "/lectures/lec8-inner-game/"
  },"87": {
    "doc": "Lecture 9 - Combining Forecasts",
    "title": "Lecture 9: Combining Forecasts",
    "content": "Often there are multiple ways to forecast the same thing, and we'd like a way of combining the forecasts together. For instance, consider the following question: . Will Will be among the top 3 most sold nonfiction books on Amazon for the week of November 21? . (This was posed to the course staff at the beginning of that week.) . I approached this problem using reference class forecasting, but there wasn't any single very good reference class. Specifically: . | I built up a dataset of the past 6 weeks by manually copying information from the website. | Will had been #1 last week and #7 two weeks prior (and not released before that). | 1 out of 3 books in the top 3 remained there the following week (15 data points total). | 1 out of 5 books in the top 1 were in the top 3 the following week (5 data points total). | Of books that were top 3 last week and top 8 the previous week, 1 out of 4 stayed in the top 3 (4 points total). | Of books that were top 1 last week and top 8 the previous week, 1 out of 2 stayed in the top 3 (2 points total). | . The problem is that: . | None of these reference classes have many data points. | The class with the most data points (“top 3 last week”) is the one that's least analogous to Will. | . One way out of this is to combine all the reference classes together in a weighted average. This is called ensembling. I'll start with a rough intuitive way of doing this and then give a more principled way (as with most things in forecasting, the best approach is to practice the principled way until it informs your intuition, then mostly go with intuitive numbers). Rough intuitive approach. Let's give each data source a score out of 10, based on how “good” it seems (a combination of the total number of data points and how analogous it is to Will). | Top 3: I give this 6 out of 10. There's a lot of data points but it's only somewhat analogous. | Top 1: I give this 3.5 out of 10. More analogous, but few enough data points to have lots of noise. | Top 3 + top 8: I give this 3 out of 10. Similar to top 1 but one fewer data point. | Top 1 + top 8: 2 out of 10. Most analogous but no data. | . Then we combine as a weighted average: $\\frac{6 \\cdot (1/3) + 4 \\cdot (1/5) + 3.5 \\cdot (1/4) + 2 \\cdot (1/2)}{6 + 4 + 3.5 + 2} = 0.30$. More principled approach. The intuitive approach is reasonable, but as written it neglects some obvious information: for instance, the fact that the “top 3” reference class should probably provide a lower bound (since Will was top 1), so we should forecast at least $5/15 = 0.33$ (instead of $0.30$ as above). We can handle this by more explicitly modeling each of the 4 estimates as “noisy” versions of the true probability. Specifically: . | Let $\\pi$ be the “true” probability that Will is top 3 next week. | For each reference class $i$, let $\\pi_i$ denote the probability for that reference class (that is, the fraction of positives we would see if we had an infinite number of samples). | Finally, let $X_i$ be the observes number of positive samples and $N_i$ the total number of samples for the reference class. So for instance $X_1 = 5$, $N_1 = 15$, and $X_2 = 1$, $N_2 = 5$. | . We will think of each $\\pi_i$ as a noisy version of $\\pi$, and $X_i$ as a noisy version of $\\pi_i$: . For instance, if $\\pi$ is the probability for Will, I might think the probability $\\pi_1$ for a generic top 3 book is somewhere in the range $[\\pi-0.2, \\pi]$. To model this, I'll treat $\\pi_1$ as a Gaussian with mean $\\pi - 0.1$ and variance $0.1^2$. In general, for each reference class $i$ we might think it has a bias $\\Delta_i$ relative to $\\pi$, and uncertainty $\\sigma_i$, modeling $\\pi_i$ as Gaussian with mean $\\pi + \\Delta_i$ and variance $\\sigma_i^2$. Here's a table of my intuitions for $\\Delta_i$ and $\\sigma_i$: . | # | Ref. Class | $\\Delta_i$ | $\\sigma_i$ | . | 1 | Top 3 | -0.1 | 0.1 | . | 2 | Top 1 | 0 | 0.1 | . | 3 | Top 3 + top 8 | 0 | 0.1 | . | 4 | Top 1 + top 8 | 0 | 0.07 | . (Brief explanation: I intuitively thought “top 1” and “top 3 + top 8” were roughly equally good reference classes for Will, while “top 1 + top 8” was a bit better, so I gave the last one lower $\\sigma_i$.) . Going from $\\pi_i$ to $\\pi$. If we knew $\\pi_1, \\ldots, \\pi_4$, then it turns out that the maximum likelihood estimate for $\\pi$ is . $\\frac{(\\pi_1 - \\Delta_1) / \\sigma_1^2 + (\\pi_2 - \\Delta_2) / \\sigma_2^2 + (\\pi_3 - \\Delta_3) / \\sigma_3^2 + (\\pi_4 - \\Delta_4) / \\sigma_4^2}{1/\\sigma_1^2 + 1/\\sigma_2^2 + 1/\\sigma_3^2 + 1/\\sigma_4^2}$. In other words, we first correct each $\\pi_i$ for its bias, then take a weighted average, weighted by the inverse of the variance. This recovers the weighting idea from the rough intuitive approach. The main advantage is that it gives us a more principled way to think about the weights $1/\\sigma_i^2$. Incorporating sample noise. However, there are still some problems. First, we don't actually know $\\pi_i$: only $X_i$ and $N_i$. We can approximate $\\pi_i$ as $\\hat{\\pi}_i = X_i / N_i$, but we also need to adjust $\\sigma_i$. For instance, the table above has $\\sigma_4$ as the smallest, meaning we would rely on it most in our average, but that reference class only has $2$ data points. Fortunately, there is a simple mathematical correction for the difference between $\\hat{\\pi}_i$ and $\\pi_i$. It relies on the assumption that $\\hat{\\pi}_i$ is an average of independent random variables (the different members of the reference class) and so can be well-approximated by a Gaussian distribution. A standard estimate of the variance of this Gaussian is $\\frac{\\hat{\\pi}_i(1-\\hat{\\pi}_i)}{N_i-1}$, so we can replace the old $\\sigma_i$ with the corrected values . $\\overline{\\sigma}\\_i^2 = \\sigma_i^2 + \\frac{\\hat{\\pi}\\_i(1 - \\hat{\\pi}\\_i)}{N_i - 1}$ . The following table summarizes these calculations: . | # | Ref. Class | $\\Delta_i$ | $\\sigma_i$ | $X_i$ | $N_i$ | $\\hat{\\pi}_i$ | $\\overline{\\sigma}_i^2$ | . | 1 | Top 3 | -0.1 | 0.1 | 5 | 15 | 0.33 | $0.1^2 + 0.016 = 0.026$ | . | 2 | Top 1 | 0 | 0.1 | 1 | 5 | 0.2 | $0.1^2 + 0.04 = 0.05$ | . | 3 | Top 3 + top 8 | 0 | 0.1 | 1 | 4 | 0.25 | $0.1^2 + 0.063 = 0.073$ | . | 4 | Top 1 + top 8 | 0 | 0.07 | 1 | 2 | 0.5 | $0.07^2 + 0.25 = 0.255$ | . Weighting the $\\pi_i - \\Delta_i$ by $1/\\overline{\\sigma}_i^2$, we get an overall estimate of $0.34$, which makes more sense than the $0.30$ forecast from before. Combining the approaches. In practice, it's probably not worth exhaustively doing the math above to compute $\\overline{\\sigma}_i$. Instead, I would in fact pick the weights based on intuition, but keep in mind that they are based on two terms: one capturing how similar the reference class is to what we care about (after correcting for bias), and one capturing finite sample error, which decreases at a rate of roughly $1/N_i$. There are two reasons that computing the weights intuitively, rather than mathematically, is usually better. The first is that the math above depends on independence assumptions that might not hold. For instance, since the “top 1” reference class is a subset of the “top 3” reference class, they are positively correlated, so I'd want to decrease the weight for “top 1” a bit since it's redundant information. After I did this, my intuitive forecast was $0.36$ rather than $0.34$. Another important reason is that it's easy to get caught up in these calculations, when it's often better to instead look at the problem from additional angles. For instance, one of the other course staff realized that autobiographies often stay in the top 3 for a while, and that Will had so far been particularly well-received within this genre, so gave a probability significantly above 50% (and ended up being right). ",
    "url": "http://localhost:4000/lectures/lec9-combining-forecasts/#lecture-9-combining-forecasts",
    "relUrl": "/lectures/lec9-combining-forecasts/#lecture-9-combining-forecasts"
  },"88": {
    "doc": "Lecture 9 - Combining Forecasts",
    "title": "Combining External Forecasts",
    "content": "We used the ideas above to aggregate different reference classes, but we can apply the same strategy of averaging predictions whenever there are multiple ways of approaching a forecasting problem. More interestingly, we can combine predictions of different forecasters. Let's say that Frances and I both make forecasts about something, but I know that so far she's had a somewhat better track record than me. Then I could probably do better than either of us by averaging our forecasts but giving hers a 3:1 weight relative to mine. (Or if she's done much better than me, 10:1; or 1:1 if we've done similarly.) You can also do this for larger teams and even for people you don't know, as long as you have a rough sense of how much to trust them. In practice, this is how I form beliefs for most topics: I identify a set of experts who have a good track record, and take a weighted average of their views. For a much smaller set of topics, I also develop my own deep “inside view”, although if I were making forecasts I would still average that view with other experts. However, when practicing forecasting, you don't want to just defer to others' forecasts all the time, since then you won't improve your own forecasting skills. You want to practice both the skill of generating your own forecasts and weighing the forecasts of others. In addition, if you are on a team of forecasters, often the most successful method is the Delphi method, where forecasters first generate predictions individually, then discuss, then generate new predictions and take the average. You'll get to practice this a lot in the group discussions this semester to get a sense for it. ",
    "url": "http://localhost:4000/lectures/lec9-combining-forecasts/#combining-external-forecasts",
    "relUrl": "/lectures/lec9-combining-forecasts/#combining-external-forecasts"
  },"89": {
    "doc": "Lecture 9 - Combining Forecasts",
    "title": "Summary",
    "content": "Ensembling–the idea of taking weighted averages of forecasts–is a powerful tool for improving over any individual forecast. When assigning weights, you want to consider both the quality of the underlying data and how closely the forecast captures the situation at hand. However, obsessing too much about how to ensemble can also distract you from searching for new information that significantly alters your view—so it's usually best to perform as a lightweight “post-processing” step. ",
    "url": "http://localhost:4000/lectures/lec9-combining-forecasts/#summary",
    "relUrl": "/lectures/lec9-combining-forecasts/#summary"
  },"90": {
    "doc": "Lecture 9 - Combining Forecasts",
    "title": "Lecture 9 - Combining Forecasts",
    "content": " ",
    "url": "http://localhost:4000/lectures/lec9-combining-forecasts/",
    "relUrl": "/lectures/lec9-combining-forecasts/"
  }
}
